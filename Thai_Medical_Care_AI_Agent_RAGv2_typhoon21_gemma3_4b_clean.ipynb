{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7f6nxNcYgzs"
      },
      "outputs": [],
      "source": [
        "# ‡∏£‡∏∞‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏° RAG\n",
        "# ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏ß‡∏µ89 ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡∏à‡∏≥‡∏Å‡∏±‡∏î\n",
        "# Version 2.0 Thai Medical Care AI Agent Chat RAG system with Multi-Modal in Google Colab T4 GPU\n",
        "\n",
        "print(\"üöÄ Installing required packages...\")\n",
        "\n",
        "# Install required packages with proper versions\n",
        "!pip install -q --upgrade pip==24.0\n",
        "!pip install -q --force-reinstall torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q compressed-tensors>=0.7.0\n",
        "!pip install -q transformers==4.50.0 accelerate==1.1.0 bitsandbytes==0.47.0\n",
        "!pip install -q numpy==2.0.2 fsspec==2025.3.2 jedi>=0.16 filelock>=3.15 typing_extensions>=4.14.0  filelock>=3.15 scipy==1.14.1 websockets==15.0.1\n",
        "!pip install -q pythainlp sentence-transformers\n",
        "!pip install -q datasets==2.20.0 evaluate rouge-score==0.1.2\n",
        "!pip install -q chromadb>=0.4.0 faiss-cpu\n",
        "!pip install -q pandas scikit-learn\n",
        "!pip install -q openai-whisper timm Pillow\n",
        "!pip install -q gradio>=4.44.1\n",
        "!pip install -q opencv-python-headless>=4.9.0.8 soundfile librosa\n",
        "!pip install -q optuna\n",
        "\n",
        "print(\"üì¶ Packages installed successfully!\")\n",
        "\n",
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline,\n",
        "    ViTImageProcessor,\n",
        "    ViTForImageClassification\n",
        ")\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import re\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import timm\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "from typing import List, Dict, Tuple, Optional, Any, Union\n",
        "import hashlib\n",
        "import sqlite3\n",
        "import os\n",
        "from pathlib import Path\n",
        "from functools import lru_cache\n",
        "import uuid\n",
        "import whisper\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import time\n",
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
        "import optuna\n",
        "import gc\n",
        "import sys\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import required libraries for RAG\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "import faiss\n",
        "\n",
        "# Setup environment\n",
        "os.environ['TRANSFORMERS_CACHE'] = '/content/cache'\n",
        "os.environ['HF_HOME'] = '/content/cache'\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "# Enable optimizations\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ CUDA available - GPU: {torch.cuda.get_device_name()}\")\n",
        "    torch.backends.cuda.enable_flash_sdp(True)\n",
        "    torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
        "    torch.backends.cuda.enable_math_sdp(True)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è CUDA not available - using CPU\")\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# Thai NLP Setup with fallback\n",
        "try:\n",
        "    from pythainlp.tokenize import word_tokenize\n",
        "    from pythainlp.corpus.common import thai_stopwords\n",
        "    from pythainlp.spell import correct\n",
        "    from pythainlp.util import normalize\n",
        "    print(\"‚úÖ PyThaiNLP imported successfully\")\n",
        "    THAI_NLP_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è PyThaiNLP setup issue: {e}\")\n",
        "    THAI_NLP_AVAILABLE = False\n",
        "\n",
        "    def word_tokenize(text, engine='basic'):\n",
        "        # Simple Thai tokenization fallback\n",
        "        import re\n",
        "        tokens = re.findall(r'[‡∏Å-‡πô]+|[a-zA-Z]+|\\d+', text)\n",
        "        return tokens if tokens else text.split()\n",
        "\n",
        "    def thai_stopwords():\n",
        "        return {'‡πÅ‡∏•‡∏∞', '‡∏´‡∏£‡∏∑‡∏≠', '‡∏ó‡∏µ‡πà', '‡πÉ‡∏ô', '‡∏à‡∏≤‡∏Å', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏°‡∏µ', '‡πÑ‡∏î‡πâ', '‡πÑ‡∏õ', '‡∏°‡∏≤'}\n",
        "\n",
        "    def correct(text):\n",
        "        return text\n",
        "\n",
        "    def normalize(text):\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive with error handling\n",
        "def setup_drive_connection():\n",
        "    \"\"\"Setup Google Drive connection with fallback\"\"\"\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        drive_path = \"/content/drive/MyDrive/V89Technology/typhoon21-gemma3-4b-medCare-finetuned/checkpoint-120\"\n",
        "        print(\"Google Drive connected successfully\")\n",
        "        return drive_path\n",
        "    except:\n",
        "        local_path = \"V89Technology/typhoon21-gemma3-4b-medCare-finetuned/checkpoint-120\"\n",
        "        os.makedirs(local_path, exist_ok=True)\n",
        "        print(\"Running outside Colab - using local directory\")\n",
        "        return local_path\n",
        "\n",
        "drive_path = setup_drive_connection()\n",
        "\n",
        "# Configuration\n",
        "GOOGLE_DRIVE_FOLDER = \"V89Technology\"\n",
        "RAG_THRESHOLD = 0.7\n",
        "MAX_TOKENS = 512\n",
        "TOP_K = 5\n",
        "PDPA_CONSENT_VERSION = \"1.0\"\n",
        "MEDICAL_STANDARD_VERSION = \"HL7_FHIR_R4\"\n",
        "CACHE_SIZE = 1000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "class GoogleDriveManager:\n",
        "    \"\"\"Simplified Google Drive Manager for demo purposes\"\"\"\n",
        "\n",
        "    def __init__(self, folder_name=GOOGLE_DRIVE_FOLDER):\n",
        "        self.folder_name = folder_name\n",
        "        self.setup_local_storage()\n",
        "\n",
        "    def setup_local_storage(self):\n",
        "        \"\"\"Setup local storage for demo\"\"\"\n",
        "        try:\n",
        "            os.makedirs(self.folder_name, exist_ok=True)\n",
        "            print(f\"‚úÖ Local storage created: {self.folder_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Storage setup failed: {e}\")\n",
        "\n",
        "    def save_patient_data(self, patient_id: str, data: dict):\n",
        "        \"\"\"Save patient data locally with PDPA compliance\"\"\"\n",
        "        try:\n",
        "            filename = os.path.join(self.folder_name, f\"patient_{patient_id}.json\")\n",
        "            encrypted_data = self.encrypt_patient_data(data)\n",
        "            with open(filename, 'w', encoding='utf-8') as f:\n",
        "                json.dump(encrypted_data, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"‚úÖ Patient data saved: {patient_id}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error saving patient data: {e}\")\n",
        "            return False\n",
        "\n",
        "    def load_patient_data(self, patient_id: str) -> dict:\n",
        "        \"\"\"Load patient data locally\"\"\"\n",
        "        try:\n",
        "            filename = os.path.join(self.folder_name, f\"patient_{patient_id}.json\")\n",
        "            if os.path.exists(filename):\n",
        "                with open(filename, 'r', encoding='utf-8') as f:\n",
        "                    encrypted_data = json.load(f)\n",
        "                return self.decrypt_patient_data(encrypted_data)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading patient data: {e}\")\n",
        "        return {}\n",
        "\n",
        "    def encrypt_patient_data(self, data: dict) -> dict:\n",
        "        \"\"\"Encrypt sensitive patient data for PDPA compliance\"\"\"\n",
        "        try:\n",
        "            return {\n",
        "                'data_hash': hashlib.sha256(json.dumps(data, ensure_ascii=False).encode()).hexdigest(),\n",
        "                'data': data,\n",
        "                'encrypted_at': datetime.now().isoformat(),\n",
        "                'pdpa_version': PDPA_CONSENT_VERSION\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error encrypting data: {e}\")\n",
        "            return data\n",
        "\n",
        "    def decrypt_patient_data(self, encrypted_data: dict) -> dict:\n",
        "        \"\"\"Decrypt patient data\"\"\"\n",
        "        try:\n",
        "            if 'data' not in encrypted_data:\n",
        "                return encrypted_data\n",
        "\n",
        "            # Verify data integrity\n",
        "            if 'data_hash' in encrypted_data:\n",
        "                current_hash = hashlib.sha256(json.dumps(encrypted_data['data'], ensure_ascii=False).encode()).hexdigest()\n",
        "                if current_hash != encrypted_data['data_hash']:\n",
        "                    print(\"‚ö†Ô∏è Data integrity check failed\")\n",
        "\n",
        "            return encrypted_data['data']\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error decrypting data: {e}\")\n",
        "            return {}\n",
        "\n",
        "class EmergencyTriageSystem:\n",
        "    \"\"\"Real-time Emergency Triage System\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.triage_criteria = {\n",
        "            'critical': ['‡πÄ‡∏à‡πá‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å', '‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å', '‡∏´‡∏°‡∏î‡∏™‡∏ï‡∏¥', '‡∏ä‡∏±‡∏Å', '‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏Å', '‡πÅ‡∏Ç‡∏ô‡∏Ç‡∏≤‡∏≠‡πà‡∏≠‡∏ô‡πÅ‡∏£‡∏á', '‡πÄ‡∏à‡πá‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á'],\n",
        "            'high': ['‡πÑ‡∏Ç‡πâ‡∏™‡∏π‡∏á', '‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á', '‡∏≠‡∏≤‡πÄ‡∏à‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î', '‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á', '‡∏ï‡∏≤‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á', '‡∏´‡∏≠‡∏ö‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢'],\n",
        "            'medium': ['‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á', '‡πÑ‡∏Ç‡πâ', '‡∏ú‡∏∑‡πà‡∏ô', '‡πÑ‡∏≠', '‡∏ô‡πâ‡∏≥‡∏°‡∏π‡∏Å', '‡∏ó‡πâ‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢'],\n",
        "            'low': ['‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢', '‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ', '‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ', '‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û']\n",
        "        }\n",
        "        self.emergency_response = {\n",
        "            'critical': '‚ö†Ô∏è ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÇ‡∏ó‡∏£ 1669 ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏õ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏ó‡∏±‡∏ô‡∏ó‡∏µ',\n",
        "            'high': '‚ö†Ô∏è ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á ‡∏Ñ‡∏ß‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏†‡∏≤‡∏¢‡πÉ‡∏ô 24 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á',\n",
        "            'medium': 'üìã ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á ‡∏Ñ‡∏ß‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏´‡∏≤‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô 2-3 ‡∏ß‡∏±‡∏ô',\n",
        "            'low': 'üí° ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ö‡πâ‡∏≤‡∏ô‡πÑ‡∏î‡πâ'\n",
        "        }\n",
        "\n",
        "    def assess_urgency(self, text, image_analysis=None, audio_analysis=None):\n",
        "        \"\"\"Assess urgency level based on input\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Check for critical keywords\n",
        "        for keyword in self.triage_criteria['critical']:\n",
        "            if keyword in text_lower:\n",
        "                return 'critical'\n",
        "\n",
        "        # Check for high priority keywords\n",
        "        high_score = sum(1 for keyword in self.triage_criteria['high'] if keyword in text_lower)\n",
        "        if high_score >= 2:\n",
        "            return 'high'\n",
        "\n",
        "        # Check for medium priority keywords\n",
        "        medium_score = sum(1 for keyword in self.triage_criteria['medium'] if keyword in text_lower)\n",
        "        if medium_score >= 1:\n",
        "            return 'medium'\n",
        "\n",
        "        return 'low'\n",
        "\n",
        "    def get_emergency_response(self, urgency_level):\n",
        "        \"\"\"Get appropriate emergency response\"\"\"\n",
        "        return self.emergency_response.get(urgency_level, 'üí° ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ö‡πâ‡∏≤‡∏ô‡πÑ‡∏î‡πâ')\n",
        "\n",
        "class AdvancedSymptomChecker:\n",
        "    \"\"\"Advanced Symptom Checker with Thai medical knowledge\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.symptom_ontology = {\n",
        "            'fever': ['‡πÑ‡∏Ç‡πâ', '‡∏ï‡∏±‡∏ß‡∏£‡πâ‡∏≠‡∏ô', '‡∏£‡πâ‡∏≠‡∏ô‡πÉ‡∏ô', '‡πÑ‡∏Ç‡πâ‡∏™‡∏π‡∏á'],\n",
        "            'headache': ['‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß', '‡∏®‡∏µ‡∏£‡∏©‡∏∞', '‡∏°‡∏∂‡∏ô‡∏´‡∏±‡∏ß', '‡∏´‡∏ô‡∏≤‡∏ß‡∏´‡∏±‡∏ß'],\n",
        "            'cough': ['‡πÑ‡∏≠', '‡πÄ‡∏™‡∏°‡∏´‡∏∞', '‡πÑ‡∏≠‡πÅ‡∏´‡πâ‡∏á', '‡πÑ‡∏≠‡∏°‡∏µ‡πÄ‡∏™‡∏°‡∏´‡∏∞'],\n",
        "            'abdominal_pain': ['‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á', '‡∏ó‡πâ‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢', '‡∏ñ‡πà‡∏≤‡∏¢‡πÄ‡∏´‡∏•‡∏ß', '‡∏õ‡∏ß‡∏î‡∏Å‡∏£‡∏∞‡πÄ‡∏û‡∏≤‡∏∞'],\n",
        "            'chest_pain': ['‡πÄ‡∏à‡πá‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å', '‡∏õ‡∏ß‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å', '‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å‡∏ï‡∏∂‡∏á'],\n",
        "            'shortness_of_breath': ['‡∏´‡∏≠‡∏ö‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢', '‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏•‡∏≥‡∏ö‡∏≤‡∏Å', '‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å'],\n",
        "            'rash': ['‡∏ú‡∏∑‡πà‡∏ô', '‡∏Ñ‡∏±‡∏ô', '‡∏•‡∏°‡∏û‡∏¥‡∏©', '‡πÅ‡∏ú‡∏•‡∏ú‡∏∑‡πà‡∏ô']\n",
        "        }\n",
        "\n",
        "        self.disease_symptom_map = {\n",
        "            'influenza': ['fever', 'headache', 'cough'],\n",
        "            'dengue': ['fever', 'headache', 'rash'],\n",
        "            'gastroenteritis': ['abdominal_pain', 'fever'],\n",
        "            'heart_attack': ['chest_pain', 'shortness_of_breath'],\n",
        "            'allergy': ['rash', 'cough']\n",
        "        }\n",
        "\n",
        "    def analyze_symptoms(self, symptoms: List[str], patient_info: Dict) -> Dict:\n",
        "        \"\"\"Analyze symptoms and provide assessment\"\"\"\n",
        "        matched_conditions = self._match_symptoms_to_conditions(symptoms)\n",
        "        risk_score = self._calculate_risk_score(symptoms, patient_info)\n",
        "\n",
        "        return {\n",
        "            'possible_conditions': matched_conditions,\n",
        "            'risk_score': risk_score,\n",
        "            'recommendations': self._generate_recommendations(matched_conditions, risk_score)\n",
        "        }\n",
        "\n",
        "    def _match_symptoms_to_conditions(self, symptoms: List[str]) -> List[str]:\n",
        "        \"\"\"Match symptoms to possible medical conditions\"\"\"\n",
        "        matched = []\n",
        "        symptom_keys = []\n",
        "\n",
        "        # Convert symptoms to ontology keys\n",
        "        for symptom in symptoms:\n",
        "            for key, thai_terms in self.symptom_ontology.items():\n",
        "                if any(term in symptom for term in thai_terms):\n",
        "                    symptom_keys.append(key)\n",
        "\n",
        "        # Find matching conditions\n",
        "        for condition, condition_symptoms in self.disease_symptom_map.items():\n",
        "            match_count = sum(1 for symptom in symptom_keys if symptom in condition_symptoms)\n",
        "            if match_count >= 1:\n",
        "                matched.append(condition)\n",
        "\n",
        "        return matched\n",
        "\n",
        "    def _calculate_risk_score(self, symptoms: List[str], patient_info: Dict) -> float:\n",
        "        \"\"\"Calculate risk score\"\"\"\n",
        "        base_score = len(symptoms) * 0.1\n",
        "        age = patient_info.get('age', 30)\n",
        "\n",
        "        if age < 5 or age > 65:\n",
        "            base_score += 0.2\n",
        "\n",
        "        if patient_info.get('medical_history'):\n",
        "            base_score += 0.2\n",
        "\n",
        "        return min(base_score, 1.0)\n",
        "\n",
        "    def _generate_recommendations(self, conditions: List[str], risk_score: float) -> List[str]:\n",
        "        \"\"\"Generate medical recommendations\"\"\"\n",
        "        recommendations = []\n",
        "\n",
        "        if risk_score > 0.7:\n",
        "            recommendations.append(\"‡∏Ñ‡∏ß‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡πá‡∏ß\")\n",
        "        elif risk_score > 0.4:\n",
        "            recommendations.append(\"‡∏Ñ‡∏ß‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏´‡∏≤‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡πà‡∏•‡∏á\")\n",
        "        else:\n",
        "            recommendations.append(\"‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏î‡∏π‡πÅ‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á\")\n",
        "\n",
        "        if 'heart_attack' in conditions:\n",
        "            recommendations.append(\"‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô! ‡πÇ‡∏ó‡∏£ 1669 ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\")\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "class EnhancedMultiModalProcessor:\n",
        "    \"\"\"Enhanced MultiModal Processor for medical analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.setup_models()\n",
        "\n",
        "    def setup_models(self):\n",
        "        \"\"\"Setup vision and audio models\"\"\"\n",
        "        # Vision model\n",
        "        try:\n",
        "            self.vision_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "            self.vision_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "            print(\"‚úÖ Vision model loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Vision model failed: {e}\")\n",
        "            self.vision_model = None\n",
        "\n",
        "        # Whisper model\n",
        "        try:\n",
        "            self.whisper_model = whisper.load_model(\"base\")\n",
        "            print(\"‚úÖ Whisper audio model loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Whisper model failed: {e}\")\n",
        "            self.whisper_model = None\n",
        "\n",
        "    def process_image(self, image_path: str) -> Dict:\n",
        "        \"\"\"Process medical image\"\"\"\n",
        "        if not self.vision_model or not image_path:\n",
        "            return {'error': 'Vision model not available or no image provided'}\n",
        "\n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            inputs = self.vision_processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.vision_model(**inputs)\n",
        "\n",
        "            logits = outputs.logits\n",
        "            predicted_class_idx = logits.argmax(-1).item()\n",
        "            confidence = torch.nn.functional.softmax(logits, dim=-1).max().item()\n",
        "\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'prediction': self.vision_model.config.id2label[predicted_class_idx],\n",
        "                'confidence': float(confidence),\n",
        "                'analysis': '‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô - ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥'\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {'error': f'Image processing failed: {str(e)}'}\n",
        "\n",
        "    def process_audio(self, audio_path: str) -> Dict:\n",
        "        \"\"\"Process audio to text using Whisper\"\"\"\n",
        "        if not self.whisper_model or not audio_path:\n",
        "            return {'error': 'Whisper model not available or no audio provided'}\n",
        "\n",
        "        try:\n",
        "            result = self.whisper_model.transcribe(audio_path)\n",
        "\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'text': result['text'],\n",
        "                'language': result.get('language', 'unknown'),\n",
        "                'confidence': 0.9  # Whisper doesn't provide confidence directly\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {'error': f'Audio processing failed: {str(e)}'}\n",
        "\n",
        "class EnhancedMedicalRAGSystem:\n",
        "    \"\"\"Enhanced RAG System with Medical Knowledge Base\"\"\"\n",
        "\n",
        "    def __init__(self, drive_manager: GoogleDriveManager):\n",
        "        self.drive_manager = drive_manager\n",
        "        self.embedding_model = None\n",
        "        self.medical_documents = []\n",
        "        self.chroma_client = None\n",
        "        self.collection = None\n",
        "        self.triage_system = EmergencyTriageSystem()\n",
        "        self.symptom_checker = AdvancedSymptomChecker()\n",
        "        self.setup_system()\n",
        "\n",
        "    def setup_system(self):\n",
        "        \"\"\"Setup the complete RAG system\"\"\"\n",
        "        self.setup_embedding_model()\n",
        "        self.setup_vector_database()\n",
        "        self.load_medical_knowledge()\n",
        "        self.process_documents_for_rag()\n",
        "\n",
        "    def setup_embedding_model(self):\n",
        "        \"\"\"Setup multilingual embedding model\"\"\"\n",
        "        try:\n",
        "            model_name = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
        "            self.embedding_model = SentenceTransformer(model_name)\n",
        "            print(\"‚úÖ Embedding model loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading embedding model: {e}\")\n",
        "\n",
        "    def setup_vector_database(self):\n",
        "        \"\"\"Setup ChromaDB vector database\"\"\"\n",
        "        try:\n",
        "            self.chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "            try:\n",
        "                self.collection = self.chroma_client.get_collection(name=\"medical_knowledge\")\n",
        "                print(\"‚úÖ Existing collection loaded\")\n",
        "            except:\n",
        "                self.collection = self.chroma_client.create_collection(\n",
        "                    name=\"medical_knowledge\",\n",
        "                    metadata={\"hnsw:space\": \"cosine\"}\n",
        "                )\n",
        "                print(\"‚úÖ New collection created\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error setting up vector database: {e}\")\n",
        "\n",
        "    def load_medical_knowledge(self):\n",
        "        \"\"\"Load comprehensive medical knowledge base\"\"\"\n",
        "        print(\"üìö Loading medical knowledge base...\")\n",
        "\n",
        "        # Thai medical standards and guidelines\n",
        "        thai_medical_data = [\n",
        "            {\n",
        "                'content': '‡πÇ‡∏õ‡∏£‡πÇ‡∏ï‡∏Ñ‡∏≠‡∏•‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô: ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡πá‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á - ‡πÉ‡∏´‡πâ‡∏≠‡∏≠‡∏Å‡∏ã‡∏¥‡πÄ‡∏à‡∏ô, ‡∏ï‡∏£‡∏ß‡∏à EKG ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ, ‡πÉ‡∏´‡πâ Aspirin 300mg ‡πÄ‡∏Ñ‡∏µ‡πâ‡∏¢‡∏ß, ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠ PCI',\n",
        "                'category': 'emergency',\n",
        "                'type': 'protocol'\n",
        "            },\n",
        "            {\n",
        "                'content': '‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ABCDE: Airway (‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏ô‡∏´‡∏≤‡∏¢‡πÉ‡∏à), Breathing (‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏¢‡πÉ‡∏à), Circulation (‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏´‡∏•‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô), Disability (‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó), Exposure (‡∏ï‡∏£‡∏ß‡∏à‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢)',\n",
        "                'category': 'emergency',\n",
        "                'type': 'assessment'\n",
        "            },\n",
        "            {\n",
        "                'content': '‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô: ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ HbA1c < 7%, FBS 80-130 mg/dL, 2hr PP < 180 mg/dL, ‡∏ï‡∏£‡∏ß‡∏à‡∏ï‡∏≤/‡πÑ‡∏ï/‡πÄ‡∏ó‡πâ‡∏≤‡∏õ‡∏µ‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á',\n",
        "                'category': 'endocrine',\n",
        "                'type': 'guideline'\n",
        "            },\n",
        "            {\n",
        "                'content': '‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡∏™‡∏π‡∏á: ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ BP < 140/90 mmHg (‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ), < 130/80 mmHg (‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô/‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ï), ‡∏õ‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏ñ‡∏µ‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï + ‡∏¢‡∏≤',\n",
        "                'category': 'cardiovascular',\n",
        "                'type': 'guideline'\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Medical Q&A data\n",
        "        medical_qa = [\n",
        "            {\n",
        "                'content': 'Q: ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÑ‡∏Ç‡πâ‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ A: ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏Ç‡πâ‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡∏ç‡πà ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà ‡πÑ‡∏Ç‡πâ‡∏™‡∏π‡∏á ‡∏´‡∏ô‡∏≤‡∏ß‡∏™‡∏±‡πà‡∏ô ‡∏õ‡∏ß‡∏î‡∏Å‡∏•‡πâ‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠ ‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß ‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÑ‡∏≠‡πÅ‡∏´‡πâ‡∏á ‡∏ô‡πâ‡∏≥‡∏°‡∏π‡∏Å‡πÑ‡∏´‡∏• ‡∏Ñ‡∏≠‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏∞‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏ß‡∏±‡∏î‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤',\n",
        "                'category': 'infectious_disease',\n",
        "                'type': 'qa'\n",
        "            },\n",
        "            {\n",
        "                'content': 'Q: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏î‡∏π‡πÅ‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô A: ‡∏Å‡∏≤‡∏£‡∏î‡∏π‡πÅ‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô: ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡πÉ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏ó‡∏≤‡∏ô‡∏¢‡∏≤‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ ‡∏≠‡∏≠‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏¢‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠ ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏ó‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡πÇ‡∏†‡∏ä‡∏ô‡∏≤‡∏Å‡∏≤‡∏£ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞',\n",
        "                'category': 'endocrine',\n",
        "                'type': 'qa'\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Drug interaction data\n",
        "        drug_interactions = [\n",
        "            {\n",
        "                'content': 'Warfarin + Aspirin: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏≠‡∏≠‡∏Å ‡∏Ñ‡∏ß‡∏£‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏¢‡∏≤‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡πà‡∏≤ INR ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏Å‡∏•‡πâ‡∏ä‡∏¥‡∏î',\n",
        "                'category': 'drug_interaction',\n",
        "                'type': 'safety'\n",
        "            },\n",
        "            {\n",
        "                'content': 'Metformin + Contrast dye: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á lactic acidosis ‡∏Ñ‡∏ß‡∏£‡∏´‡∏¢‡∏∏‡∏î metformin 48 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á‡πÉ‡∏´‡πâ contrast',\n",
        "                'category': 'drug_interaction',\n",
        "                'type': 'safety'\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Symptom-disease mapping\n",
        "        symptom_mapping = [\n",
        "            {\n",
        "                'content': '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏Ç‡πâ‡∏™‡∏π‡∏á ‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß ‡∏õ‡∏ß‡∏î‡∏Å‡∏•‡πâ‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠ ‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢‡πÑ‡∏Ç‡πâ‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡∏ç‡πà ‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à Rapid influenza test ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏≠‡∏≤‡∏Å‡∏≤‡∏£',\n",
        "                'category': 'diagnostic',\n",
        "                'type': 'symptom_mapping'\n",
        "            },\n",
        "            {\n",
        "                'content': '‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏Ñ‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏™‡πâ‡∏≠‡∏≤‡πÄ‡∏à‡∏µ‡∏¢‡∏ô ‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏Å‡∏£‡∏∞‡πÄ‡∏û‡∏≤‡∏∞‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏£‡∏î‡πÑ‡∏´‡∏•‡∏¢‡πâ‡∏≠‡∏ô ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏¢‡∏≤‡∏•‡∏î‡∏Å‡∏£‡∏î',\n",
        "                'category': 'diagnostic',\n",
        "                'type': 'symptom_mapping'\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Combine all medical data\n",
        "        all_medical_data = thai_medical_data + medical_qa + drug_interactions + symptom_mapping\n",
        "\n",
        "        # Convert to document format\n",
        "        for item in all_medical_data:\n",
        "            self.medical_documents.append({\n",
        "                'content': item['content'],\n",
        "                'metadata': {\n",
        "                    'source': 'medical_knowledge_base',\n",
        "                    'category': item['category'],\n",
        "                    'type': item['type'],\n",
        "                    'language': 'thai',\n",
        "                    'updated': datetime.now().isoformat()\n",
        "                }\n",
        "            })\n",
        "\n",
        "        print(f\"‚úÖ Loaded {len(self.medical_documents)} medical documents\")\n",
        "\n",
        "    def process_documents_for_rag(self):\n",
        "        \"\"\"Process and index documents for RAG\"\"\"\n",
        "        if not self.embedding_model or not self.collection:\n",
        "            print(\"‚ùå Cannot process documents - missing components\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            print(f\"üìä Processing {len(self.medical_documents)} documents for RAG...\")\n",
        "\n",
        "            # Clear existing collection\n",
        "            try:\n",
        "                self.collection.delete(where={})\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Process in batches to avoid memory issues\n",
        "            batch_size = 50\n",
        "            for i in range(0, len(self.medical_documents), batch_size):\n",
        "                batch = self.medical_documents[i:i+batch_size]\n",
        "\n",
        "                contents = [doc['content'] for doc in batch]\n",
        "                embeddings = self.embedding_model.encode(contents).tolist()\n",
        "\n",
        "                # Add to ChromaDB\n",
        "                self.collection.add(\n",
        "                    documents=contents,\n",
        "                    embeddings=embeddings,\n",
        "                    metadatas=[doc['metadata'] for doc in batch],\n",
        "                    ids=[str(uuid.uuid4()) for _ in batch]\n",
        "                )\n",
        "\n",
        "            print(f\"‚úÖ Successfully indexed {len(self.medical_documents)} documents\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing documents: {e}\")\n",
        "\n",
        "    def retrieve_relevant_documents(self, query: str, top_k: int = 5) -> List[Dict]:\n",
        "        \"\"\"Retrieve relevant medical documents\"\"\"\n",
        "        if not self.embedding_model or not self.collection:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            query_embedding = self.embedding_model.encode([query]).tolist()[0]\n",
        "\n",
        "            results = self.collection.query(\n",
        "                query_embeddings=[query_embedding],\n",
        "                n_results=top_k\n",
        "            )\n",
        "\n",
        "            relevant_docs = []\n",
        "            if results and results['documents']:\n",
        "                for i, doc in enumerate(results['documents'][0]):\n",
        "                    relevant_docs.append({\n",
        "                        'content': doc,\n",
        "                        'metadata': results['metadatas'][0][i] if results['metadatas'] else {},\n",
        "                        'score': 1 - results['distances'][0][i] if results['distances'] else 0.5\n",
        "                    })\n",
        "\n",
        "            return relevant_docs\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error retrieving documents: {e}\")\n",
        "            return []\n",
        "\n",
        "    def generate_medical_response(self, query: str, patient_info: Dict = None) -> Dict:\n",
        "        \"\"\"Generate comprehensive medical response\"\"\"\n",
        "        if not patient_info:\n",
        "            patient_info = {}\n",
        "\n",
        "        # Retrieve relevant knowledge\n",
        "        relevant_docs = self.retrieve_relevant_documents(query, top_k=TOP_K)\n",
        "\n",
        "        # Assess urgency\n",
        "        urgency_level = self.triage_system.assess_urgency(query)\n",
        "        emergency_response = self.triage_system.get_emergency_response(urgency_level)\n",
        "\n",
        "        # Analyze symptoms\n",
        "        symptoms = self._extract_symptoms(query)\n",
        "        symptom_analysis = self.symptom_checker.analyze_symptoms(symptoms, patient_info)\n",
        "\n",
        "        # Generate response\n",
        "        response = self._format_comprehensive_response(\n",
        "            query=query,\n",
        "            relevant_docs=relevant_docs,\n",
        "            urgency_level=urgency_level,\n",
        "            emergency_response=emergency_response,\n",
        "            symptom_analysis=symptom_analysis\n",
        "        )\n",
        "\n",
        "        return response\n",
        "\n",
        "    def _extract_symptoms(self, text: str) -> List[str]:\n",
        "        \"\"\"Extract symptoms from Thai text\"\"\"\n",
        "        symptoms = []\n",
        "        symptom_keywords = [\n",
        "            '‡∏õ‡∏ß‡∏î', '‡πÑ‡∏Ç‡πâ', '‡∏£‡πâ‡∏≠‡∏ô', '‡∏´‡∏ô‡∏≤‡∏ß', '‡πÑ‡∏≠', '‡∏à‡∏≤‡∏°', '‡∏ô‡πâ‡∏≥‡∏°‡∏π‡∏Å',\n",
        "            '‡∏Ñ‡∏±‡∏î‡∏à‡∏°‡∏π‡∏Å', '‡πÄ‡∏à‡πá‡∏ö', '‡∏Ñ‡∏±‡∏ô', '‡∏ú‡∏∑‡πà‡∏ô', '‡πÅ‡∏î‡∏á', '‡∏ö‡∏ß‡∏°',\n",
        "            '‡∏Ñ‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏™‡πâ', '‡∏≠‡∏≤‡πÄ‡∏à‡∏µ‡∏¢‡∏ô', '‡∏ó‡πâ‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢', '‡∏ó‡πâ‡∏≠‡∏á‡∏ú‡∏π‡∏Å',\n",
        "            '‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô‡∏´‡∏±‡∏ß', '‡∏°‡∏∂‡∏ô‡∏´‡∏±‡∏ß', '‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢', '‡∏≠‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏•‡∏µ‡∏¢',\n",
        "            '‡∏´‡∏≠‡∏ö‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢', '‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏•‡∏≥‡∏ö‡∏≤‡∏Å'\n",
        "        ]\n",
        "\n",
        "        for keyword in symptom_keywords:\n",
        "            if keyword in text:\n",
        "                # Extract context around symptom\n",
        "                start = max(0, text.find(keyword) - 15)\n",
        "                end = min(len(text), text.find(keyword) + len(keyword) + 15)\n",
        "                symptom_phrase = text[start:end].strip()\n",
        "                symptoms.append(symptom_phrase)\n",
        "\n",
        "        return symptoms\n",
        "\n",
        "    def _format_comprehensive_response(self, **kwargs) -> Dict:\n",
        "        \"\"\"Format comprehensive medical response\"\"\"\n",
        "        response_parts = []\n",
        "\n",
        "        # Emergency alert\n",
        "        if kwargs['urgency_level'] in ['critical', 'high']:\n",
        "            response_parts.append(f\"üö® {kwargs['emergency_response']}\")\n",
        "\n",
        "        # Relevant medical information\n",
        "        if kwargs['relevant_docs']:\n",
        "            response_parts.append(\"üìö **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:**\")\n",
        "            for doc in kwargs['relevant_docs'][:3]:  # Top 3 relevant docs\n",
        "                if doc['score'] > RAG_THRESHOLD:\n",
        "                    response_parts.append(f\"- {doc['content'][:200]}...\")\n",
        "\n",
        "        # Symptom analysis\n",
        "        if kwargs['symptom_analysis']['possible_conditions']:\n",
        "            response_parts.append(\"üîç **‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£:**\")\n",
        "            conditions = ', '.join(kwargs['symptom_analysis']['possible_conditions'])\n",
        "            response_parts.append(f\"‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö: {conditions}\")\n",
        "\n",
        "        # Recommendations\n",
        "        if kwargs['symptom_analysis']['recommendations']:\n",
        "            response_parts.append(\"üí° **‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**\")\n",
        "            for rec in kwargs['symptom_analysis']['recommendations']:\n",
        "                response_parts.append(f\"- {rec}\")\n",
        "\n",
        "        # Medical disclaimer\n",
        "        response_parts.append(\"\\n‚ö†Ô∏è **‡∏Ç‡πâ‡∏≠‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö:** ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\")\n",
        "\n",
        "        return {\n",
        "            'response': '\\n\\n'.join(response_parts),\n",
        "            'urgency_level': kwargs['urgency_level'],\n",
        "            'confidence': kwargs['symptom_analysis']['risk_score'],\n",
        "            'relevant_sources': len(kwargs['relevant_docs']),\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "class ThaiMedicalAIAgent:\n",
        "    \"\"\"Main Thai Medical AI Agent with complete functionality\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"üè• Initializing Thai Medical AI Agent...\")\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"üíª Using device: {self.device}\")\n",
        "\n",
        "        # Initialize components\n",
        "        self.drive_manager = GoogleDriveManager()\n",
        "        self.rag_system = EnhancedMedicalRAGSystem(self.drive_manager)\n",
        "        self.multimodal_processor = EnhancedMultiModalProcessor()\n",
        "\n",
        "        # Initialize language model\n",
        "        self.setup_language_model()\n",
        "\n",
        "        # Patient session management\n",
        "        self.current_patient = {}\n",
        "        self.conversation_history = []\n",
        "\n",
        "        print(\"‚úÖ Thai Medical AI Agent initialized successfully!\")\n",
        "\n",
        "    def setup_language_model(self):\n",
        "        \"\"\"Load typhoon21-gemma3-4b model with PEFT adapter medical fine-tuning\"\"\"\n",
        "        try:\n",
        "            base_model_name = \"scb10x/typhoon2.1-gemma3-4b\"\n",
        "            adapter_path = \"/content/drive/MyDrive/V89Technology/typhoon21-gemma3-4b-medCare-finetuned/checkpoint-120\"\n",
        "\n",
        "            # Configure for T4 GPU efficiency\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "                bnb_4bit_quant_type=\"nf4\"\n",
        "            )\n",
        "\n",
        "            # Load tokenizer\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "            # Load base model\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                base_model_name,\n",
        "               quantization_config=quantization_config,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                trust_remote_code=True,\n",
        "                low_cpu_mem_usage=True\n",
        "            )\n",
        "\n",
        "            # Load PEFT adapter\n",
        "            from peft import PeftModel\n",
        "            self.model = PeftModel.from_pretrained(\n",
        "                self.model,\n",
        "                adapter_path,\n",
        "                adapter_name=\"medical_adapter\"\n",
        "            )\n",
        "\n",
        "            # Set model to evaluation mode\n",
        "            self.model.eval()\n",
        "\n",
        "            print(\"‚úÖ typhoon21-gemma3-4b model with medical PEFT adapter loaded successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading typhoon21-gemma3-4b LLM: {e}\")\n",
        "            # Fallback to pipeline\n",
        "            try:\n",
        "                self.pipeline = pipeline(\n",
        "                    \"text-generation\",\n",
        "                    model=\"scb10x/typhoon2.1-gemma3-4b\",\n",
        "                    device=0 if torch.cuda.is_available() else -1\n",
        "                )\n",
        "                self.model = None\n",
        "                self.tokenizer = None\n",
        "                print(\"‚úÖ Fallback model loaded\")\n",
        "            except:\n",
        "                self.model = None\n",
        "                self.tokenizer = None\n",
        "                self.pipeline = None\n",
        "                print(\"‚ùå No language model available\")\n",
        "\n",
        "    def process_patient_info(self, name: str, age: int, gender: str, medical_history: str,\n",
        "                           current_symptoms: str, consent_pdpa: bool) -> str:\n",
        "        \"\"\"Process and store patient information with PDPA compliance\"\"\"\n",
        "        if not consent_pdpa:\n",
        "            return \"‚ùå ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ï‡∏≤‡∏° ‡∏û.‡∏£.‡∏ö. PDPA ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£\"\n",
        "\n",
        "        try:\n",
        "            # Generate patient ID\n",
        "            patient_id = str(uuid.uuid4())[:8]\n",
        "\n",
        "            # Store patient information\n",
        "            patient_data = {\n",
        "                'patient_id': patient_id,\n",
        "                'name': name,\n",
        "                'age': age,\n",
        "                'gender': gender,\n",
        "                'medical_history': medical_history,\n",
        "                'current_symptoms': current_symptoms,\n",
        "                'created_at': datetime.now().isoformat(),\n",
        "                'pdpa_consent': consent_pdpa,\n",
        "                'pdpa_version': PDPA_CONSENT_VERSION\n",
        "            }\n",
        "\n",
        "            # Save to secure storage\n",
        "            success = self.drive_manager.save_patient_data(patient_id, patient_data)\n",
        "\n",
        "            if success:\n",
        "                self.current_patient = patient_data\n",
        "\n",
        "                # Initial triage assessment\n",
        "                urgency = self.rag_system.triage_system.assess_urgency(current_symptoms)\n",
        "\n",
        "                response = f\"\"\"‚úÖ **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß**\n",
        "\n",
        "üë§ **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ:**\n",
        "- ID: {patient_id}\n",
        "- ‡∏ä‡∏∑‡πà‡∏≠: {name}\n",
        "- ‡∏≠‡∏≤‡∏¢‡∏∏: {age} ‡∏õ‡∏µ\n",
        "- ‡πÄ‡∏û‡∏®: {gender}\n",
        "\n",
        "üè• **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô:**\n",
        "- ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô: {urgency}\n",
        "- {self.rag_system.triage_system.get_emergency_response(urgency)}\n",
        "\n",
        "üí¨ **‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤:** ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢\n",
        "\"\"\"\n",
        "\n",
        "                return response\n",
        "            else:\n",
        "                return \"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing patient info: {e}\")\n",
        "            return f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}\"\n",
        "\n",
        "    def process_chat(self, user_input: str, chat_history: List) -> Tuple[str, List]:\n",
        "        \"\"\"Process chat with medical context and RAG\"\"\"\n",
        "        try:\n",
        "            if not user_input.strip():\n",
        "                return \"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°\", chat_history\n",
        "\n",
        "            # Generate medical response using RAG\n",
        "            medical_response = self.rag_system.generate_medical_response(\n",
        "                query=user_input,\n",
        "                patient_info=self.current_patient\n",
        "            )\n",
        "\n",
        "            # Enhanced response with LLM if available\n",
        "            if self.model and self.tokenizer:\n",
        "                enhanced_response = self._enhance_response_with_llm(\n",
        "                    user_input, medical_response['response']\n",
        "                )\n",
        "            else:\n",
        "                enhanced_response = medical_response['response']\n",
        "\n",
        "            # Update conversation history\n",
        "            chat_history.append((user_input, enhanced_response))\n",
        "            self.conversation_history.append({\n",
        "                'user': user_input,\n",
        "                'assistant': enhanced_response,\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'urgency_level': medical_response['urgency_level']\n",
        "            })\n",
        "\n",
        "            return enhanced_response, chat_history\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}\"\n",
        "            chat_history.append((user_input, error_msg))\n",
        "            return error_msg, chat_history\n",
        "\n",
        "    def _enhance_response_with_llm(self, user_input: str, rag_response: str) -> str:\n",
        "        \"\"\"Enhance RAG response with language model\"\"\"\n",
        "        try:\n",
        "            # Create medical context prompt\n",
        "            system_prompt = \"\"\"‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏û‡∏ó‡∏¢‡πå AI ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÉ‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏°‡∏±‡∏î‡∏£‡∏∞‡∏ß‡∏±‡∏á ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\"\"\"\n",
        "\n",
        "            # Combine context\n",
        "            context = f\"{system_prompt}\\n\\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: {rag_response}\\n\\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {user_input}\\n\\n‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:\"\n",
        "\n",
        "            # Tokenize\n",
        "            inputs = self.tokenizer.encode(context, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                inputs = inputs.to(self.device)\n",
        "\n",
        "            # Generate response\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    inputs,\n",
        "                    max_length=inputs.shape[1] + 150,\n",
        "                    temperature=0.7,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.pad_token_id,\n",
        "                    eos_token_id=self.tokenizer.eos_token_id,\n",
        "                    no_repeat_ngram_size=3\n",
        "                )\n",
        "\n",
        "            # Decode response\n",
        "            generated = self.tokenizer.decode(outputs[0][inputs.shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "            # Clean and format response\n",
        "            if generated.strip():\n",
        "                return f\"{rag_response}\\n\\nüí≠ **‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:** {generated.strip()}\"\n",
        "            else:\n",
        "                return rag_response\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è LLM enhancement failed: {e}\")\n",
        "            return rag_response\n",
        "\n",
        "    def process_image(self, image_file) -> str:\n",
        "        \"\"\"Process medical image\"\"\"\n",
        "        if image_file is None:\n",
        "            return \"‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û\"\n",
        "\n",
        "        try:\n",
        "            # Save uploaded image temporarily\n",
        "            temp_path = f\"/tmp/uploaded_image_{int(time.time())}.jpg\"\n",
        "\n",
        "            # Handle different input types\n",
        "            if hasattr(image_file, 'name'):\n",
        "                # Gradio file object\n",
        "                image = Image.open(image_file.name)\n",
        "            else:\n",
        "                # Direct path or PIL image\n",
        "                image = Image.open(image_file) if isinstance(image_file, str) else image_file\n",
        "\n",
        "            # Convert to RGB and save\n",
        "            image = image.convert('RGB')\n",
        "            image.save(temp_path)\n",
        "\n",
        "            # Process with multimodal processor\n",
        "            result = self.multimodal_processor.process_image(temp_path)\n",
        "\n",
        "            # Clean up\n",
        "            try:\n",
        "                os.remove(temp_path)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            if 'error' in result:\n",
        "                return f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {result['error']}\"\n",
        "            else:\n",
        "                return f\"\"\"üìä **‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û:**\n",
        "\n",
        "üîç **‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏âM‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô:** {result['prediction']}\n",
        "üìà **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à:** {result['confidence']:.2%}\n",
        "üí° **‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** {result['analysis']}\n",
        "\n",
        "‚ö†Ô∏è **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏ô‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
        "\"\"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û: {str(e)}\"\n",
        "\n",
        "    def process_audio(self, audio_file) -> str:\n",
        "        \"\"\"Process audio input\"\"\"\n",
        "        if audio_file is None:\n",
        "            return \"‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á\"\n",
        "\n",
        "        try:\n",
        "            # Process audio with Whisper\n",
        "            result = self.multimodal_processor.process_audio(audio_file)\n",
        "\n",
        "            if 'error' in result:\n",
        "                return f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {result['error']}\"\n",
        "            else:\n",
        "                # Continue with chat processing using transcribed text\n",
        "                transcribed_text = result['text']\n",
        "                response, _ = self.process_chat(transcribed_text, [])\n",
        "\n",
        "                return f\"\"\"üé§ **‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á:** {transcribed_text}\n",
        "\n",
        "{response}\n",
        "\"\"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {str(e)}\"\n",
        "\n",
        "    def get_patient_summary(self) -> str:\n",
        "        \"\"\"Get current patient summary\"\"\"\n",
        "        if not self.current_patient:\n",
        "            return \"‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö\"\n",
        "\n",
        "        patient = self.current_patient\n",
        "        return f\"\"\"üìã **‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢:**\n",
        "\n",
        "üë§ **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß:**\n",
        "- ID: {patient.get('patient_id', 'N/A')}\n",
        "- ‡∏ä‡∏∑‡πà‡∏≠: {patient.get('name', 'N/A')}\n",
        "- ‡∏≠‡∏≤‡∏¢‡∏∏: {patient.get('age', 'N/A')} ‡∏õ‡∏µ\n",
        "- ‡πÄ‡∏û‡∏®: {patient.get('gender', 'N/A')}\n",
        "\n",
        "üè• **‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û:**\n",
        "{patient.get('medical_history', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•')}\n",
        "\n",
        "ü§í **‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô:**\n",
        "{patient.get('current_symptoms', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•')}\n",
        "\n",
        "üìÖ **‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠:** {patient.get('created_at', 'N/A')}\n",
        "\"\"\"\n",
        "\n",
        "    def clear_conversation(self) -> str:\n",
        "        \"\"\"Clear conversation history\"\"\"\n",
        "        self.conversation_history = []\n",
        "        return \"üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß\"\n",
        "\n",
        "    def emergency_triage(self, symptoms: str) -> str:\n",
        "        \"\"\"Emergency triage assessment\"\"\"\n",
        "        urgency = self.rag_system.triage_system.assess_urgency(symptoms)\n",
        "        response = self.rag_system.triage_system.get_emergency_response(urgency)\n",
        "\n",
        "        return f\"\"\"üö® **‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô:**\n",
        "\n",
        "üîç **‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô:** {symptoms}\n",
        "üìä **‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô:** {urgency}\n",
        "üí° **‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** {response}\n",
        "\n",
        "{'üöë **‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÇ‡∏ó‡∏£ 1669 ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏õ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏ó‡∏±‡∏ô‡∏ó‡∏µ**' if urgency == 'critical' else '‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏Å‡∏•‡πâ‡∏ä‡∏¥‡∏î'}\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the AI Agent\n",
        "ai_agent = ThaiMedicalAIAgent()\n",
        "\n",
        "# Create Gradio interface\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create comprehensive Gradio interface\"\"\"\n",
        "\n",
        "    with gr.Blocks(\n",
        "        title=\"Thai Medical Care AI Agent - V89 Technology\",\n",
        "        theme=gr.themes.Soft(),\n",
        "        css=\"\"\"\n",
        "        .medical-chat { background-color: #f0f8ff; }\n",
        "        .emergency { background-color: #ffcccc; padding: 10px; border-radius: 5px; }\n",
        "        .success { background-color: #ccffcc; padding: 10px; border-radius: 5px; }\n",
        "        .warning { background-color: #ffffcc; padding: 10px; border-radius: 5px; }\n",
        "        \"\"\"\n",
        "    ) as demo:\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        # üè• Thai Medical Care AI Agent Chat with RAG System\n",
        "        ### **‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏ß‡∏µ89 ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡∏à‡∏≥‡∏Å‡∏±‡∏î** | **üìà‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** 2.0 - ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: ‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏° 2025\n",
        "\n",
        "        ü§ñ  ‡∏£‡∏∞‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏° RAG\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Tab(\"üìã ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢\"):\n",
        "            gr.Markdown(\"### üìù ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    name_input = gr.Textbox(label=\"‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•\", placeholder=\"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏∞‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•\")\n",
        "                    age_input = gr.Number(label=\"‡∏≠‡∏≤‡∏¢‡∏∏\", minimum=0, maximum=120)\n",
        "                    gender_input = gr.Radio(choices=[\"‡∏ä‡∏≤‡∏¢\", \"‡∏´‡∏ç‡∏¥‡∏á\", \"‡∏≠‡∏∑‡πà‡∏ô‡πÜ\"], label=\"‡πÄ‡∏û‡∏®\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    medical_history_input = gr.Textbox(\n",
        "                        label=\"‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡πá‡∏ö‡∏õ‡πà‡∏ß‡∏¢\",\n",
        "                        placeholder=\"‡πÇ‡∏£‡∏Ñ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ï‡∏±‡∏ß, ‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡πâ‡∏¢‡∏≤, ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î ‡∏Ø‡∏•‡∏Ø\",\n",
        "                        lines=3\n",
        "                    )\n",
        "                    current_symptoms_input = gr.Textbox(\n",
        "                        label=\"‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\",\n",
        "                        placeholder=\"‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏≠‡∏¢‡∏π‡πà\",\n",
        "                        lines=3\n",
        "                    )\n",
        "                    consent_checkbox = gr.Checkbox(\n",
        "                        label=\"‡∏â‡∏±‡∏ô‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° ‡∏û.‡∏£.‡∏ö. ‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• ‡∏û.‡∏®. 2562\",\n",
        "                        value=True\n",
        "                    )\n",
        "\n",
        "            register_btn = gr.Button(\"‚úÖ ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢\", variant=\"primary\")\n",
        "            patient_output = gr.Markdown()\n",
        "\n",
        "            register_btn.click(\n",
        "                ai_agent.process_patient_info,\n",
        "                inputs=[name_input, age_input, gender_input, medical_history_input, current_symptoms_input, consent_checkbox],\n",
        "                outputs=patient_output\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"üí¨ ‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå AI\"):\n",
        "            gr.Markdown(\"### üí¨ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏û‡∏ó‡∏¢‡πå AI\")\n",
        "\n",
        "            chatbot = gr.Chatbot(\n",
        "                label=\"‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤\",\n",
        "                height=400,\n",
        "                elem_classes=\"medical-chat\"\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                msg = gr.Textbox(\n",
        "                    label=\"‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\",\n",
        "                    placeholder=\"‡πÄ‡∏ä‡πà‡∏ô '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏â‡∏±‡∏ô‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡πÑ‡∏Ç‡πâ ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏î‡∏µ?'\",\n",
        "                    scale=4\n",
        "                )\n",
        "                send_btn = gr.Button(\"üì§ ‡∏™‡πà‡∏á\", scale=1)\n",
        "\n",
        "            with gr.Row():\n",
        "                clear_btn = gr.Button(\"üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤\")\n",
        "                summary_btn = gr.Button(\"üìã ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢\")\n",
        "\n",
        "            patient_summary = gr.Markdown()\n",
        "\n",
        "            def respond(message, chat_history):\n",
        "                response, updated_chat = ai_agent.process_chat(message, chat_history)\n",
        "                return updated_chat\n",
        "\n",
        "            msg.submit(respond, [msg, chatbot], [chatbot])\n",
        "            send_btn.click(respond, [msg, chatbot], [chatbot])\n",
        "            clear_btn.click(lambda: None, None, [chatbot], queue=False)\n",
        "            clear_btn.click(ai_agent.clear_conversation, None, [patient_summary])\n",
        "            summary_btn.click(ai_agent.get_patient_summary, None, [patient_summary])\n",
        "\n",
        "        with gr.Tab(\"üñºÔ∏è ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û\"):\n",
        "            gr.Markdown(\"### üñºÔ∏è ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\")\n",
        "\n",
        "            with gr.Row():\n",
        "                image_input = gr.Image(\n",
        "                    label=\"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û\",\n",
        "                    type=\"filepath\",\n",
        "                    sources=[\"upload\", \"webcam\"]\n",
        "                )\n",
        "                image_output = gr.Markdown()\n",
        "\n",
        "            analyze_btn = gr.Button(\"üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û\", variant=\"primary\")\n",
        "            analyze_btn.click(ai_agent.process_image, inputs=[image_input], outputs=[image_output])\n",
        "\n",
        "        with gr.Tab(\"üé§ ‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á\"):\n",
        "            gr.Markdown(\"### üé§ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á\")\n",
        "\n",
        "            with gr.Row():\n",
        "                audio_input = gr.Audio(\n",
        "                    label=\"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á\",\n",
        "                    sources=[\"upload\", \"microphone\"],\n",
        "                    type=\"filepath\"\n",
        "                )\n",
        "                audio_output = gr.Markdown()\n",
        "\n",
        "            process_audio_btn = gr.Button(\"üîä ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á\", variant=\"primary\")\n",
        "            process_audio_btn.click(ai_agent.process_audio, inputs=[audio_input], outputs=[audio_output])\n",
        "\n",
        "        with gr.Tab(\"üö® ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô\"):\n",
        "            gr.Markdown(\"### üö® ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô\")\n",
        "\n",
        "            emergency_input = gr.Textbox(\n",
        "                label=\"‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô\",\n",
        "                placeholder=\"‡πÄ‡∏ä‡πà‡∏ô '‡πÄ‡∏à‡πá‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å'\",\n",
        "                lines=3\n",
        "            )\n",
        "            emergency_output = gr.Markdown()\n",
        "\n",
        "            triage_btn = gr.Button(\"‚ö†Ô∏è ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏≠‡∏≤‡∏Å‡∏≤‡∏£\", variant=\"stop\")\n",
        "            triage_btn.click(ai_agent.emergency_triage, inputs=[emergency_input], outputs=[emergency_output])\n",
        "\n",
        "        with gr.Tab(\"‚ÑπÔ∏è ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö\"):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### ‚ÑπÔ∏è ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö ‡∏£‡∏∞‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏° RAG\n",
        "\n",
        "            **‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏Å:**\n",
        "            - ü§ñ ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
        "            - üè• ‡∏£‡∏∞‡∏ö‡∏ö RAG (Retrieval Augmented Generation) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå\n",
        "            - üìö ‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "            - üñºÔ∏è ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
        "            - üé§ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏û‡∏π‡∏î\n",
        "            - üö® ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô\n",
        "            - üîí ‡∏Å‡∏≤‡∏£‡∏õ‡∏Å‡∏õ‡πâ‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ï‡∏≤‡∏° PDPA\n",
        "\n",
        "            **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:**\n",
        "            - **‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** 2.0\n",
        "            - **‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:** ‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏° 2025\n",
        "            - **‡∏ú‡∏π‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤:** ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏ß‡∏µ89 ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡∏à‡∏≥‡∏Å‡∏±‡∏î\n",
        "            - **‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå:** HL7 FHIR R4\n",
        "            - **‡∏Å‡∏≤‡∏£‡∏õ‡∏Å‡∏õ‡πâ‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** PDPA Compliance\n",
        "\n",
        "            **‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö:**\n",
        "            ‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
        "            ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Å‡∏≤‡∏£‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç\n",
        "            ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\n",
        "            \"\"\")\n",
        "\n",
        "        # Footer\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        **‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢ ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏ß‡∏µ89 ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡∏à‡∏≥‡∏Å‡∏±‡∏î** | üìß ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠: support@v89.tech | üìû ‡πÇ‡∏ó‡∏£: 02-XXX-XXXX\n",
        "\n",
        "        *‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô*\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Create and launch the interface\n",
        "print(\"üé® Creating Gradio interface...\")\n",
        "demo = create_gradio_interface()\n",
        "\n",
        "print(\"üöÄ Launching the application...\")\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(\n",
        "        server_name=\"0.0.0.0\",\n",
        "        #server_port=7860,\n",
        "        share=True,\n",
        "        debug=False\n",
        "    )"
      ],
      "metadata": {
        "id": "rWCRfdR2YhbH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}