{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-2Z2UJDWGL4"
      },
      "outputs": [],
      "source": [
        "# ‡∏£‡∏∞‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "# ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏ß‡∏µ89 ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡∏à‡∏≥‡∏Å‡∏±‡∏î\n",
        "# Enhanced Thai Medical Care AI Agent Chat with CoT, v2.0 - With typhoon2.1-gemma3-4b, Vision, Audio\n",
        "\n",
        "print(\"üöÄ Installing required packages...\")\n",
        "\n",
        "# üì¶ Install required packages for Python 3.12.11 compatibility\n",
        "!pip install -q --upgrade pip==24.0\n",
        "!pip install -q --force-reinstall torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q compressed-tensors>=0.7.0\n",
        "!pip install -q transformers==4.50.0 accelerate==1.1.0 bitsandbytes==0.47.0\n",
        "!pip install -q numpy==2.0.2 scipy==1.14.1 fsspec==2025.3.2 rich==12.4.4 pandas==2.2.2\n",
        "!pip install -q gradio pythainlp sentence-transformers\n",
        "!pip install -q  datasets==2.20.0 evaluate==0.4.1 rouge-score==0.1.2\n",
        "!pip install -q openai-whisper pillow timm\n",
        "!pip install -q sqlalchemy cryptography bcrypt\n",
        "!pip install -q opencv-python-headless>=4.9.0.80 librosa soundfile\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q matplotlib\n",
        "#!pip install -q flash-attn --no-build-isolation\n",
        "\n",
        "print(\"üì¶ Packages installed successfully!\")\n",
        "\n",
        "import torch\n",
        "import gradio as gr\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    pipeline,\n",
        "    ViTImageProcessor,\n",
        "    ViTForImageClassification,\n",
        "    WhisperProcessor,\n",
        "    WhisperForConditionalGeneration,\n",
        "    AutoProcessor,\n",
        "    AutoImageProcessor,\n",
        "    AutoModelForImageClassification,\n",
        ")\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import hashlib\n",
        "import sqlite3\n",
        "import pickle\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from enum import Enum\n",
        "import warnings\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from cryptography.fernet import Fernet\n",
        "import base64\n",
        "import uuid\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import evaluate\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import Thai NLP libraries\n",
        "try:\n",
        "    from pythainlp.tokenize import word_tokenize\n",
        "    from pythainlp.corpus.common import thai_stopwords\n",
        "    THAI_NLP_AVAILABLE = True\n",
        "except:\n",
        "    THAI_NLP_AVAILABLE = False\n",
        "    def word_tokenize(text, engine='basic'):\n",
        "        return text.split()\n",
        "    def thai_stopwords():\n",
        "        return set()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive with error handling\n",
        "def setup_drive_connection():\n",
        "    \"\"\"Setup Google Drive connection with fallback\"\"\"\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        drive_path = \"/content/drive/MyDrive/V89Technology/typhoon21-gemma3-4b-medCare-finetuned/checkpoint-120\"\n",
        "        print(\"Google Drive connected successfully\")\n",
        "        return drive_path\n",
        "    except:\n",
        "        local_path = \"V89Technology/typhoon21-gemma3-4b-medCare-finetuned/checkpoint-120\"\n",
        "        os.makedirs(local_path, exist_ok=True)\n",
        "        print(\"Running outside Colab - using local directory\")\n",
        "        return local_path\n",
        "\n",
        "drive_path = setup_drive_connection()\n",
        "\n",
        "# ========================= Enhanced Enums and Data Classes =========================\n",
        "\n",
        "class MedicalDomain(Enum):\n",
        "    EMERGENCY = \"emergency\"\n",
        "    DIAGNOSIS = \"diagnosis\"\n",
        "    TREATMENT = \"treatment\"\n",
        "    MEDICATION = \"medication\"\n",
        "    PREVENTION = \"prevention\"\n",
        "    SYMPTOM_ASSESSMENT = \"symptom_assessment\"\n",
        "    IMAGE_ANALYSIS = \"image_analysis\"\n",
        "    VOICE_ANALYSIS = \"voice_analysis\"\n",
        "\n",
        "class UrgencyLevel(Enum):\n",
        "    CRITICAL = \"critical\"\n",
        "    HIGH = \"high\"\n",
        "    MEDIUM = \"medium\"\n",
        "    LOW = \"low\"\n",
        "\n",
        "class ConsentType(Enum):\n",
        "    DATA_COLLECTION = \"data_collection\"\n",
        "    DATA_PROCESSING = \"data_processing\"\n",
        "    DATA_SHARING = \"data_sharing\"\n",
        "    IMAGE_PROCESSING = \"image_processing\"\n",
        "    VOICE_PROCESSING = \"voice_processing\"\n",
        "\n",
        "@dataclass\n",
        "class UserConsent:\n",
        "    user_id: str\n",
        "    consent_type: ConsentType\n",
        "    granted: bool\n",
        "    timestamp: datetime\n",
        "    ip_address: str = \"\"\n",
        "    details: Dict = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class UserProfile:\n",
        "    user_id: str\n",
        "    created_at: datetime\n",
        "    name: str = \"\"\n",
        "    age: int = 0\n",
        "    gender: str = \"\"\n",
        "    medical_history: List[str] = field(default_factory=list)\n",
        "    current_medications: List[str] = field(default_factory=list)\n",
        "    allergies: List[str] = field(default_factory=list)\n",
        "    emergency_contact: str = \"\"\n",
        "    consents: List[UserConsent] = field(default_factory=list)\n",
        "    encrypted_data: Dict = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class InteractionFeedback:\n",
        "    interaction_id: str\n",
        "    user_id: str\n",
        "    timestamp: datetime\n",
        "    rating: int  # 1-5\n",
        "    helpful: bool\n",
        "    accurate: bool\n",
        "    comments: str = \"\"\n",
        "    symptoms_resolved: bool = False\n",
        "    follow_up_needed: bool = False\n",
        "\n",
        "@dataclass\n",
        "class ClarificationQuestion:\n",
        "    question_id: str\n",
        "    category: str\n",
        "    question_text: str\n",
        "    options: List[str]\n",
        "    required: bool = False\n",
        "    follow_up_questions: List[str] = field(default_factory=list)\n",
        "\n",
        "# ========================= PDPA Compliance and Security =========================\n",
        "\n",
        "class PDPACompliance:\n",
        "    \"\"\"Handle PDPA compliance and data protection\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.encryption_key = Fernet.generate_key()\n",
        "        self.cipher = Fernet(self.encryption_key)\n",
        "        self.consent_database = {}\n",
        "        self.audit_log = []\n",
        "\n",
        "    def encrypt_sensitive_data(self, data: str) -> str:\n",
        "        \"\"\"Encrypt sensitive personal data\"\"\"\n",
        "        encrypted = self.cipher.encrypt(data.encode())\n",
        "        return base64.b64encode(encrypted).decode()\n",
        "\n",
        "    def decrypt_sensitive_data(self, encrypted_data: str) -> str:\n",
        "        \"\"\"Decrypt sensitive personal data\"\"\"\n",
        "        try:\n",
        "            decoded = base64.b64decode(encrypted_data.encode())\n",
        "            decrypted = self.cipher.decrypt(decoded)\n",
        "            return decrypted.decode()\n",
        "        except:\n",
        "            return \"\"\n",
        "\n",
        "    def request_consent(self, user_id: str, consent_type: ConsentType) -> Dict:\n",
        "        \"\"\"Request user consent for data processing\"\"\"\n",
        "        consent_id = str(uuid.uuid4())\n",
        "        consent_request = {\n",
        "            \"consent_id\": consent_id,\n",
        "            \"user_id\": user_id,\n",
        "            \"type\": consent_type.value,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"message\": self._get_consent_message(consent_type),\n",
        "            \"options\": [\"‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°\", \"‡πÑ‡∏°‡πà‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°\"]\n",
        "        }\n",
        "        return consent_request\n",
        "\n",
        "    def _get_consent_message(self, consent_type: ConsentType) -> str:\n",
        "        \"\"\"Get consent message in Thai\"\"\"\n",
        "        messages = {\n",
        "            ConsentType.DATA_COLLECTION: \"‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå\",\n",
        "            ConsentType.DATA_PROCESSING: \"‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\",\n",
        "            ConsentType.DATA_SHARING: \"‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏±‡∏ö‡∏ö‡∏∏‡∏Ñ‡∏•‡∏≤‡∏Å‡∏£‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå\",\n",
        "            ConsentType.IMAGE_PROCESSING: \"‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå\",\n",
        "            ConsentType.VOICE_PROCESSING: \"‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£\"\n",
        "        }\n",
        "        return messages.get(consent_type, \"‡∏Ç‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£\")\n",
        "\n",
        "    def record_consent(self, user_consent: UserConsent):\n",
        "        \"\"\"Record user consent decision\"\"\"\n",
        "        if user_consent.user_id not in self.consent_database:\n",
        "            self.consent_database[user_consent.user_id] = []\n",
        "        self.consent_database[user_consent.user_id].append(user_consent)\n",
        "\n",
        "        # Add to audit log\n",
        "        self.audit_log.append({\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"action\": \"consent_recorded\",\n",
        "            \"user_id\": user_consent.user_id,\n",
        "            \"consent_type\": user_consent.consent_type.value,\n",
        "            \"granted\": user_consent.granted\n",
        "        })\n",
        "\n",
        "    def check_consent(self, user_id: str, consent_type: ConsentType) -> bool:\n",
        "        \"\"\"Check if user has given consent\"\"\"\n",
        "        if user_id not in self.consent_database:\n",
        "            return False\n",
        "\n",
        "        user_consents = self.consent_database[user_id]\n",
        "        for consent in reversed(user_consents):  # Check most recent first\n",
        "            if consent.consent_type == consent_type:\n",
        "                return consent.granted\n",
        "        return False\n",
        "\n",
        "    def anonymize_data(self, data: Dict) -> Dict:\n",
        "        \"\"\"Anonymize personal data for storage\"\"\"\n",
        "        anonymized = data.copy()\n",
        "        sensitive_fields = ['name', 'phone', 'email', 'address', 'id_card']\n",
        "\n",
        "        for field in sensitive_fields:\n",
        "            if field in anonymized:\n",
        "                anonymized[field] = hashlib.sha256(str(anonymized[field]).encode()).hexdigest()[:8]\n",
        "\n",
        "        return anonymized\n",
        "\n",
        "# ========================= User Profile Storage System =========================\n",
        "\n",
        "class UserProfileStorage:\n",
        "    \"\"\"Secure user profile storage with PDPA compliance\"\"\"\n",
        "\n",
        "    def __init__(self, db_path: str = \"medical_profiles.db\"):\n",
        "        self.db_path = db_path\n",
        "        self.pdpa = PDPACompliance()\n",
        "        self.init_database()\n",
        "\n",
        "    def init_database(self):\n",
        "        \"\"\"Initialize SQLite database for user profiles\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Create users table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS users (\n",
        "                user_id TEXT PRIMARY KEY,\n",
        "                created_at TIMESTAMP,\n",
        "                encrypted_profile TEXT,\n",
        "                last_updated TIMESTAMP\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Create interactions table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS interactions (\n",
        "                interaction_id TEXT PRIMARY KEY,\n",
        "                user_id TEXT,\n",
        "                timestamp TIMESTAMP,\n",
        "                interaction_type TEXT,\n",
        "                encrypted_data TEXT,\n",
        "                FOREIGN KEY (user_id) REFERENCES users (user_id)\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Create feedback table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS feedback (\n",
        "                feedback_id TEXT PRIMARY KEY,\n",
        "                interaction_id TEXT,\n",
        "                user_id TEXT,\n",
        "                timestamp TIMESTAMP,\n",
        "                rating INTEGER,\n",
        "                helpful BOOLEAN,\n",
        "                accurate BOOLEAN,\n",
        "                comments TEXT,\n",
        "                FOREIGN KEY (interaction_id) REFERENCES interactions (interaction_id)\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def create_user_profile(self, user_data: Dict) -> UserProfile:\n",
        "        \"\"\"Create a new user profile with consent\"\"\"\n",
        "        user_id = str(uuid.uuid4())\n",
        "        profile = UserProfile(\n",
        "            user_id=user_id,\n",
        "            created_at=datetime.now(),\n",
        "            name=user_data.get('name', ''),\n",
        "            age=user_data.get('age', 0),\n",
        "            gender=user_data.get('gender', ''),\n",
        "            medical_history=user_data.get('medical_history', []),\n",
        "            current_medications=user_data.get('medications', []),\n",
        "            allergies=user_data.get('allergies', []),\n",
        "            emergency_contact=user_data.get('emergency_contact', '')\n",
        "        )\n",
        "\n",
        "        # Encrypt sensitive data\n",
        "        encrypted_profile = self.pdpa.encrypt_sensitive_data(\n",
        "            json.dumps(asdict(profile), default=str)\n",
        "        )\n",
        "\n",
        "        # Store in database\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute('''\n",
        "            INSERT INTO users (user_id, created_at, encrypted_profile, last_updated)\n",
        "            VALUES (?, ?, ?, ?)\n",
        "        ''', (user_id, datetime.now(), encrypted_profile, datetime.now()))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "        return profile\n",
        "\n",
        "    def get_user_profile(self, user_id: str) -> Optional[UserProfile]:\n",
        "        \"\"\"Retrieve user profile with decryption\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute('SELECT encrypted_profile FROM users WHERE user_id = ?', (user_id,))\n",
        "        result = cursor.fetchone()\n",
        "        conn.close()\n",
        "\n",
        "        if result:\n",
        "            decrypted_data = self.pdpa.decrypt_sensitive_data(result[0])\n",
        "            if decrypted_data:\n",
        "                profile_dict = json.loads(decrypted_data)\n",
        "                return UserProfile(**profile_dict)\n",
        "        return None\n",
        "\n",
        "    def update_user_profile(self, user_id: str, updates: Dict):\n",
        "        \"\"\"Update user profile with audit trail\"\"\"\n",
        "        profile = self.get_user_profile(user_id)\n",
        "        if profile:\n",
        "            for key, value in updates.items():\n",
        "                if hasattr(profile, key):\n",
        "                    setattr(profile, key, value)\n",
        "\n",
        "            # Encrypt and save\n",
        "            encrypted_profile = self.pdpa.encrypt_sensitive_data(\n",
        "                json.dumps(asdict(profile), default=str)\n",
        "            )\n",
        "\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute('''\n",
        "                UPDATE users SET encrypted_profile = ?, last_updated = ?\n",
        "                WHERE user_id = ?\n",
        "            ''', (encrypted_profile, datetime.now(), user_id))\n",
        "            conn.commit()\n",
        "            conn.close()\n",
        "\n",
        "    def store_interaction(self, user_id: str, interaction_data: Dict) -> str:\n",
        "        \"\"\"Store user interaction with encryption\"\"\"\n",
        "        interaction_id = str(uuid.uuid4())\n",
        "        encrypted_data = self.pdpa.encrypt_sensitive_data(json.dumps(interaction_data))\n",
        "\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute('''\n",
        "            INSERT INTO interactions (interaction_id, user_id, timestamp, interaction_type, encrypted_data)\n",
        "            VALUES (?, ?, ?, ?, ?)\n",
        "        ''', (interaction_id, user_id, datetime.now(), interaction_data.get('type', 'chat'), encrypted_data))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "        return interaction_id\n",
        "\n",
        "    def store_feedback(self, feedback: InteractionFeedback):\n",
        "        \"\"\"Store user feedback for improvement\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute('''\n",
        "            INSERT INTO feedback (feedback_id, interaction_id, user_id, timestamp, rating, helpful, accurate, comments)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        ''', (\n",
        "            str(uuid.uuid4()),\n",
        "            feedback.interaction_id,\n",
        "            feedback.user_id,\n",
        "            feedback.timestamp,\n",
        "            feedback.rating,\n",
        "            feedback.helpful,\n",
        "            feedback.accurate,\n",
        "            feedback.comments\n",
        "        ))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "# ========================= Real-time Emergency Triage System =========================\n",
        "\n",
        "class EmergencyTriageSystem:\n",
        "    def __init__(self):\n",
        "        self.triage_criteria = {\n",
        "            'critical': ['‡πÄ‡∏à‡πá‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å', '‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å', '‡∏´‡∏°‡∏î‡∏™‡∏ï‡∏¥', '‡∏ä‡∏±‡∏Å'],\n",
        "            'high': ['‡πÑ‡∏Ç‡πâ‡∏™‡∏π‡∏á', '‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á', '‡∏≠‡∏≤‡πÄ‡∏à‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î'],\n",
        "            'medium': ['‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á', '‡πÑ‡∏Ç‡πâ', '‡∏ú‡∏∑‡πà‡∏ô'],\n",
        "            'low': ['‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢', '‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ']\n",
        "        }\n",
        "\n",
        "    def assess_urgency(self, text, image_analysis=None):\n",
        "        score = 0\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        for keyword in self.triage_criteria['critical']:\n",
        "            if keyword in text_lower:\n",
        "                return 'critical'\n",
        "\n",
        "        # Advanced scoring logic\n",
        "        if image_analysis and 'abnormal' in image_analysis.get('prediction', '').lower():\n",
        "            score += 2\n",
        "\n",
        "        return 'high' if score >= 2 else 'medium' if score >= 1 else 'low'\n",
        "\n",
        "# ========================= Medication Interaction Checker =========================\n",
        "\n",
        "class DrugInteractionChecker:\n",
        "    def __init__(self):\n",
        "        self.interaction_db = {\n",
        "            'warfarin': ['aspirin', 'nsaids', 'antibiotics'],\n",
        "            'metformin': ['contrast', 'alcohol'],\n",
        "            'ace_inhibitors': ['potassium', 'diuretics']\n",
        "        }\n",
        "\n",
        "    def check_interactions(self, current_meds, new_meds):\n",
        "        interactions = []\n",
        "        for med in new_meds:\n",
        "            if med in self.interaction_db:\n",
        "                for existing_med in current_meds:\n",
        "                    if existing_med in self.interaction_db[med]:\n",
        "                        interactions.append(f\"{med} + {existing_med}\")\n",
        "        return interactions\n",
        "\n",
        "# ========================= Multimodal Processing Components =========================\n",
        "\n",
        "class VisionAnalyzer:\n",
        "    \"\"\"Vision Transformer for medical image analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        try:\n",
        "            # Load Vision Transformer\n",
        "            self.processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "            self.model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224').to(self.device)\n",
        "            self.model.eval()\n",
        "            print(\"‚úÖ Vision Transformer loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not load Vision Transformer: {e}\")\n",
        "            self.processor = None\n",
        "            self.model = None\n",
        "\n",
        "    def analyze_image(self, image_path: str) -> Dict:\n",
        "        \"\"\"Analyze medical image and return findings\"\"\"\n",
        "        if not self.model:\n",
        "            return {\"error\": \"Vision model not available\"}\n",
        "\n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            inputs = self.processor(images=image, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                logits = outputs.logits\n",
        "                predicted_class_idx = logits.argmax(-1).item()\n",
        "                confidence = torch.nn.functional.softmax(logits, dim=-1)[0][predicted_class_idx].item()\n",
        "\n",
        "            # Medical image analysis results\n",
        "            analysis = {\n",
        "                \"image_type\": \"medical_image\",\n",
        "                \"findings\": [],\n",
        "                \"confidence\": confidence,\n",
        "                \"recommendations\": []\n",
        "            }\n",
        "\n",
        "            # Analyze for common medical conditions in images\n",
        "            analysis[\"findings\"] = self._interpret_medical_image(image, predicted_class_idx)\n",
        "\n",
        "            return analysis\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Image analysis failed: {str(e)}\"}\n",
        "\n",
        "    def _interpret_medical_image(self, image: Image, class_idx: int) -> List[str]:\n",
        "        \"\"\"Interpret medical findings from image\"\"\"\n",
        "        findings = []\n",
        "\n",
        "        # Basic image analysis (would be more sophisticated in production)\n",
        "        img_array = np.array(image)\n",
        "\n",
        "        # Check for redness (potential inflammation)\n",
        "        red_channel = img_array[:,:,0]\n",
        "        if np.mean(red_channel) > 150:\n",
        "            findings.append(\"‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏≠‡∏¢‡πÅ‡∏î‡∏á\")\n",
        "\n",
        "        # Check for dark spots\n",
        "        gray = np.mean(img_array, axis=2)\n",
        "        if np.std(gray) > 50:\n",
        "            findings.append(\"‡∏û‡∏ö‡∏à‡∏∏‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥\")\n",
        "\n",
        "        return findings if findings else [\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\"]\n",
        "\n",
        "class AudioAnalyzer:\n",
        "    \"\"\"Whisper model for voice/audio analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        try:\n",
        "            # Load smaller Whisper model for efficiency\n",
        "            self.processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
        "            self.model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\").to(self.device)\n",
        "            self.model.eval()\n",
        "            print(\"‚úÖ Whisper model loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Could not load Whisper model: {e}\")\n",
        "            self.processor = None\n",
        "            self.model = None\n",
        "\n",
        "    def analyze_audio(self, audio_path: str) -> Dict:\n",
        "        \"\"\"Analyze audio for medical symptoms\"\"\"\n",
        "        if not self.model:\n",
        "            return {\"error\": \"Audio model not available\"}\n",
        "\n",
        "        try:\n",
        "            # Load audio\n",
        "            audio, sample_rate = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "            # Transcribe audio\n",
        "            inputs = self.processor(audio, sampling_rate=sample_rate, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                predicted_ids = self.model.generate(inputs.input_features)\n",
        "                transcription = self.processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "            # Analyze audio characteristics\n",
        "            audio_features = self._analyze_audio_features(audio, sample_rate)\n",
        "\n",
        "            return {\n",
        "                \"transcription\": transcription,\n",
        "                \"audio_features\": audio_features,\n",
        "                \"medical_indicators\": self._detect_medical_indicators(audio_features)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": f\"Audio analysis failed: {str(e)}\"}\n",
        "\n",
        "    def _analyze_audio_features(self, audio: np.ndarray, sample_rate: int) -> Dict:\n",
        "        \"\"\"Extract audio features for medical analysis\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        # Analyze cough patterns\n",
        "        features[\"energy\"] = np.mean(np.abs(audio))\n",
        "        features[\"zero_crossing_rate\"] = np.mean(librosa.feature.zero_crossing_rate(audio))\n",
        "\n",
        "        # Spectral features\n",
        "        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sample_rate)\n",
        "        features[\"spectral_centroid\"] = np.mean(spectral_centroids)\n",
        "\n",
        "        # MFCC for voice quality\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
        "        features[\"mfcc_mean\"] = np.mean(mfccs, axis=1).tolist()\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _detect_medical_indicators(self, audio_features: Dict) -> List[str]:\n",
        "        \"\"\"Detect medical indicators from audio features\"\"\"\n",
        "        indicators = []\n",
        "\n",
        "        # Check for cough patterns\n",
        "        if audio_features.get(\"zero_crossing_rate\", 0) > 0.1:\n",
        "            indicators.append(\"‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏≠\")\n",
        "\n",
        "        # Check for wheezing (high frequency)\n",
        "        if audio_features.get(\"spectral_centroid\", 0) > 3000:\n",
        "            indicators.append(\"‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏ß‡∏µ‡∏î\")\n",
        "\n",
        "        # Check for voice hoarseness\n",
        "        if audio_features.get(\"energy\", 0) < 0.01:\n",
        "            indicators.append(\"‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏´‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡πà‡∏≠‡∏ô‡πÅ‡∏£‡∏á\")\n",
        "\n",
        "        return indicators\n",
        "\n",
        "# ========================= Clarification System =========================\n",
        "\n",
        "class ClarificationSystem:\n",
        "    \"\"\"System for asking follow-up questions\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.question_templates = self._init_question_templates()\n",
        "        self.asked_questions = set()\n",
        "\n",
        "    def _init_question_templates(self) -> Dict[str, List[ClarificationQuestion]]:\n",
        "        \"\"\"Initialize clarification question templates\"\"\"\n",
        "        return {\n",
        "            \"pain\": [\n",
        "                ClarificationQuestion(\n",
        "                    question_id=\"pain_level\",\n",
        "                    category=\"severity\",\n",
        "                    question_text=\"‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏à‡πá‡∏ö‡∏õ‡∏ß‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ (1-10)?\",\n",
        "                    options=[\"1-3 (‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢)\", \"4-6 (‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á)\", \"7-9 (‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á)\", \"10 (‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏°‡∏≤‡∏Å)\"],\n",
        "                    required=True\n",
        "                ),\n",
        "                ClarificationQuestion(\n",
        "                    question_id=\"pain_duration\",\n",
        "                    category=\"duration\",\n",
        "                    question_text=\"‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏õ‡∏ß‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏°‡∏≤‡∏ô‡∏≤‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£?\",\n",
        "                    options=[\"‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á\", \"1-6 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á\", \"6-24 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á\", \"1-3 ‡∏ß‡∏±‡∏ô\", \"‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 3 ‡∏ß‡∏±‡∏ô\"],\n",
        "                    required=True\n",
        "                ),\n",
        "                ClarificationQuestion(\n",
        "                    question_id=\"pain_type\",\n",
        "                    category=\"characteristics\",\n",
        "                    question_text=\"‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏ß‡∏î‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡πÑ‡∏´‡∏ô?\",\n",
        "                    options=[\"‡∏õ‡∏ß‡∏î‡∏ï‡∏∏‡πâ‡∏ö‡πÜ\", \"‡∏õ‡∏ß‡∏î‡πÅ‡∏™‡∏ö‡∏£‡πâ‡∏≠‡∏ô\", \"‡∏õ‡∏ß‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏ß\", \"‡∏õ‡∏ß‡∏î‡∏ï‡∏∑‡πâ‡∏≠‡πÜ\", \"‡∏õ‡∏ß‡∏î‡∏ö‡∏µ‡∏ö‡∏£‡∏±‡∏î\"],\n",
        "                    required=False\n",
        "                )\n",
        "            ],\n",
        "            \"fever\": [\n",
        "                ClarificationQuestion(\n",
        "                    question_id=\"fever_temp\",\n",
        "                    category=\"measurement\",\n",
        "                    question_text=\"‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£ (‡∏ñ‡πâ‡∏≤‡∏ß‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß)?\",\n",
        "                    options=[\"37-37.5¬∞C\", \"37.5-38¬∞C\", \"38-39¬∞C\", \"39-40¬∞C\", \"‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 40¬∞C\", \"‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ß‡∏±‡∏î\"],\n",
        "                    required=True\n",
        "                ),\n",
        "                ClarificationQuestion(\n",
        "                    question_id=\"fever_pattern\",\n",
        "                    category=\"pattern\",\n",
        "                    question_text=\"‡πÑ‡∏Ç‡πâ‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?\",\n",
        "                    options=[\"‡πÑ‡∏Ç‡πâ‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤\", \"‡πÑ‡∏Ç‡πâ‡∏Ç‡∏∂‡πâ‡∏ô‡πÜ‡∏•‡∏á‡πÜ\", \"‡πÑ‡∏Ç‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô‡πÄ‡∏¢‡πá‡∏ô\", \"‡πÑ‡∏Ç‡πâ‡∏´‡∏ô‡∏≤‡∏ß‡∏™‡∏±‡πà‡∏ô\"],\n",
        "                    required=False\n",
        "                )\n",
        "            ],\n",
        "            \"respiratory\": [\n",
        "                ClarificationQuestion(\n",
        "                    question_id=\"breathing_difficulty\",\n",
        "                    category=\"severity\",\n",
        "                    question_text=\"‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏•‡∏≥‡∏ö‡∏≤‡∏Å‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô?\",\n",
        "                    options=[\"‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏õ‡∏Å‡∏ï‡∏¥\", \"‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏≠‡∏Å‡πÅ‡∏£‡∏á\", \"‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏î‡∏¥‡∏ô\", \"‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤\", \"‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å\"],\n",
        "                    required=True,\n",
        "                    follow_up_questions=[\"cough_type\", \"sputum_color\"]\n",
        "                )\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    def generate_clarification(self, symptoms: List[str], context: Dict) -> Optional[ClarificationQuestion]:\n",
        "        \"\"\"Generate appropriate clarification question based on symptoms\"\"\"\n",
        "        for symptom in symptoms:\n",
        "            # Find relevant questions for the symptom\n",
        "            symptom_key = self._map_symptom_to_category(symptom)\n",
        "            if symptom_key in self.question_templates:\n",
        "                questions = self.question_templates[symptom_key]\n",
        "\n",
        "                # Find unasked required questions\n",
        "                for question in questions:\n",
        "                    if question.question_id not in self.asked_questions:\n",
        "                        if question.required or self._should_ask_optional(question, context):\n",
        "                            self.asked_questions.add(question.question_id)\n",
        "                            return question\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _map_symptom_to_category(self, symptom: str) -> str:\n",
        "        \"\"\"Map symptom to question category\"\"\"\n",
        "        mappings = {\n",
        "            \"pain\": [\"‡∏õ‡∏ß‡∏î\", \"‡πÄ‡∏à‡πá‡∏ö\", \"pain\", \"ache\"],\n",
        "            \"fever\": [\"‡πÑ‡∏Ç‡πâ\", \"‡∏£‡πâ‡∏≠‡∏ô\", \"fever\", \"hot\"],\n",
        "            \"respiratory\": [\"‡∏´‡∏≤‡∏¢‡πÉ‡∏à\", \"‡πÑ‡∏≠\", \"‡∏´‡∏≠‡∏ö\", \"breath\", \"cough\"]\n",
        "        }\n",
        "\n",
        "        for category, keywords in mappings.items():\n",
        "            if any(keyword in symptom.lower() for keyword in keywords):\n",
        "                return category\n",
        "\n",
        "        return \"general\"\n",
        "\n",
        "    def _should_ask_optional(self, question: ClarificationQuestion, context: Dict) -> bool:\n",
        "        \"\"\"Determine if optional question should be asked\"\"\"\n",
        "        # Ask optional questions based on severity or other factors\n",
        "        severity = context.get(\"severity\", \"unknown\")\n",
        "        if severity in [\"severe\", \"‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á\"]:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def process_answer(self, question_id: str, answer: str) -> Dict:\n",
        "        \"\"\"Process user's answer to clarification question\"\"\"\n",
        "        return {\n",
        "            \"question_id\": question_id,\n",
        "            \"answer\": answer,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"processed\": True\n",
        "        }\n",
        "\n",
        "# ========================= Feedback and Learning System =========================\n",
        "\n",
        "class FeedbackLearningSystem:\n",
        "    \"\"\"System for collecting feedback and automated labeling\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.feedback_store = []\n",
        "        self.labeled_data = []\n",
        "        self.model_performance = {\n",
        "            \"accuracy\": 0.0,\n",
        "            \"helpful_rate\": 0.0,\n",
        "            \"total_interactions\": 0\n",
        "        }\n",
        "\n",
        "    def collect_feedback(self, interaction_id: str, user_id: str, feedback_data: Dict) -> InteractionFeedback:\n",
        "        \"\"\"Collect user feedback\"\"\"\n",
        "        feedback = InteractionFeedback(\n",
        "            interaction_id=interaction_id,\n",
        "            user_id=user_id,\n",
        "            timestamp=datetime.now(),\n",
        "            rating=feedback_data.get(\"rating\", 3),\n",
        "            helpful=feedback_data.get(\"helpful\", False),\n",
        "            accurate=feedback_data.get(\"accurate\", False),\n",
        "            comments=feedback_data.get(\"comments\", \"\"),\n",
        "            symptoms_resolved=feedback_data.get(\"symptoms_resolved\", False),\n",
        "            follow_up_needed=feedback_data.get(\"follow_up_needed\", False)\n",
        "        )\n",
        "\n",
        "        self.feedback_store.append(feedback)\n",
        "        self._update_performance_metrics(feedback)\n",
        "\n",
        "        return feedback\n",
        "\n",
        "    def _update_performance_metrics(self, feedback: InteractionFeedback):\n",
        "        \"\"\"Update model performance metrics\"\"\"\n",
        "        self.model_performance[\"total_interactions\"] += 1\n",
        "\n",
        "        # Calculate running averages\n",
        "        n = self.model_performance[\"total_interactions\"]\n",
        "\n",
        "        # Update accuracy\n",
        "        if feedback.accurate:\n",
        "            self.model_performance[\"accuracy\"] = (\n",
        "                (self.model_performance[\"accuracy\"] * (n - 1) + 1) / n\n",
        "            )\n",
        "        else:\n",
        "            self.model_performance[\"accuracy\"] = (\n",
        "                (self.model_performance[\"accuracy\"] * (n - 1)) / n\n",
        "            )\n",
        "\n",
        "        # Update helpful rate\n",
        "        if feedback.helpful:\n",
        "            self.model_performance[\"helpful_rate\"] = (\n",
        "                (self.model_performance[\"helpful_rate\"] * (n - 1) + 1) / n\n",
        "            )\n",
        "        else:\n",
        "            self.model_performance[\"helpful_rate\"] = (\n",
        "                (self.model_performance[\"helpful_rate\"] * (n - 1)) / n\n",
        "            )\n",
        "\n",
        "    def auto_label_interaction(self, interaction_data: Dict) -> Dict:\n",
        "        \"\"\"Automatically label interaction data for training\"\"\"\n",
        "        labels = {\n",
        "            \"interaction_id\": interaction_data.get(\"id\"),\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"auto_labels\": []\n",
        "        }\n",
        "\n",
        "        # Extract symptoms mentioned\n",
        "        text = interaction_data.get(\"text\", \"\").lower()\n",
        "\n",
        "        # Symptom detection\n",
        "        symptom_keywords = {\n",
        "            \"pain\": [\"‡∏õ‡∏ß‡∏î\", \"‡πÄ‡∏à‡πá‡∏ö\", \"pain\", \"ache\"],\n",
        "            \"fever\": [\"‡πÑ‡∏Ç‡πâ\", \"‡∏£‡πâ‡∏≠‡∏ô\", \"fever\"],\n",
        "            \"cough\": [\"‡πÑ‡∏≠\", \"cough\"],\n",
        "            \"fatigue\": [\"‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢\", \"‡∏≠‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏•‡∏µ‡∏¢\", \"tired\"]\n",
        "        }\n",
        "\n",
        "        for symptom, keywords in symptom_keywords.items():\n",
        "            if any(keyword in text for keyword in keywords):\n",
        "                labels[\"auto_labels\"].append({\n",
        "                    \"type\": \"symptom\",\n",
        "                    \"value\": symptom,\n",
        "                    \"confidence\": 0.8\n",
        "                })\n",
        "\n",
        "        # Urgency detection\n",
        "        if any(word in text for word in [\"‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô\", \"‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô\", \"‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á\", \"emergency\"]):\n",
        "            labels[\"auto_labels\"].append({\n",
        "                \"type\": \"urgency\",\n",
        "                \"value\": \"high\",\n",
        "                \"confidence\": 0.9\n",
        "            })\n",
        "\n",
        "        # Domain classification\n",
        "        if \"‡∏¢‡∏≤\" in text or \"medication\" in text:\n",
        "            labels[\"auto_labels\"].append({\n",
        "                \"type\": \"domain\",\n",
        "                \"value\": \"medication\",\n",
        "                \"confidence\": 0.85\n",
        "            })\n",
        "\n",
        "        self.labeled_data.append(labels)\n",
        "        return labels\n",
        "\n",
        "    def generate_training_data(self) -> List[Dict]:\n",
        "        \"\"\"Generate training data from feedback and auto-labels\"\"\"\n",
        "        training_data = []\n",
        "\n",
        "        for feedback in self.feedback_store:\n",
        "            if feedback.rating >= 4 and feedback.accurate:\n",
        "                # Use highly-rated accurate interactions for training\n",
        "                interaction_labels = next(\n",
        "                    (item for item in self.labeled_data\n",
        "                     if item[\"interaction_id\"] == feedback.interaction_id),\n",
        "                    None\n",
        "                )\n",
        "\n",
        "                if interaction_labels:\n",
        "                    training_data.append({\n",
        "                        \"interaction_id\": feedback.interaction_id,\n",
        "                        \"labels\": interaction_labels[\"auto_labels\"],\n",
        "                        \"feedback\": {\n",
        "                            \"rating\": feedback.rating,\n",
        "                            \"helpful\": feedback.helpful,\n",
        "                            \"accurate\": feedback.accurate\n",
        "                        },\n",
        "                        \"quality_score\": feedback.rating / 5.0\n",
        "                    })\n",
        "\n",
        "        return training_data\n",
        "\n",
        "    def get_performance_report(self) -> Dict:\n",
        "        \"\"\"Generate performance report\"\"\"\n",
        "        return {\n",
        "            \"metrics\": self.model_performance,\n",
        "            \"total_feedback\": len(self.feedback_store),\n",
        "            \"labeled_interactions\": len(self.labeled_data),\n",
        "            \"average_rating\": sum(f.rating for f in self.feedback_store) / len(self.feedback_store) if self.feedback_store else 0,\n",
        "            \"accuracy_rate\": self.model_performance[\"accuracy\"],\n",
        "            \"helpful_rate\": self.model_performance[\"helpful_rate\"]\n",
        "        }\n",
        "\n",
        "# ========================= Enhanced Medical Knowledge Base =========================\n",
        "\n",
        "class EnhancedMedicalKnowledgeBase:\n",
        "    \"\"\"Enhanced medical knowledge with Thai and English support\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.emergency_symptoms = {\n",
        "            'critical': [\n",
        "                '‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å', '‡πÄ‡∏à‡πá‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å', '‡∏ä‡∏±‡∏Å', '‡∏´‡∏°‡∏î‡∏™‡∏ï‡∏¥',\n",
        "                '‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏Å', 'breathing difficulty', 'chest pain',\n",
        "                'seizure', 'unconscious', 'severe bleeding'\n",
        "            ],\n",
        "            'high': [\n",
        "                '‡πÑ‡∏Ç‡πâ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å', '‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á', '‡∏≠‡∏≤‡πÄ‡∏à‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î',\n",
        "                'high fever', 'severe abdominal pain', 'vomiting blood'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        self.symptom_disease_mapping = {\n",
        "            '‡πÑ‡∏Ç‡πâ': ['‡πÑ‡∏Ç‡πâ‡∏´‡∏ß‡∏±‡∏î', '‡πÑ‡∏Ç‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏≠‡∏≠‡∏Å', '‡πÇ‡∏Ñ‡∏ß‡∏¥‡∏î-19', '‡πÑ‡∏Ç‡πâ‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡∏ç‡πà'],\n",
        "            '‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß': ['‡πÑ‡∏°‡πÄ‡∏Å‡∏£‡∏ô', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡∏™‡∏π‡∏á', '‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î'],\n",
        "            '‡πÑ‡∏≠': ['‡∏´‡∏ß‡∏±‡∏î', '‡∏†‡∏π‡∏°‡∏¥‡πÅ‡∏û‡πâ', '‡∏´‡∏≠‡∏ö‡∏´‡∏∑‡∏î', '‡∏õ‡∏≠‡∏î‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö'],\n",
        "            'fever': ['flu', 'dengue', 'COVID-19', 'influenza'],\n",
        "            'headache': ['migraine', 'hypertension', 'stress'],\n",
        "            'cough': ['cold', 'allergy', 'asthma', 'pneumonia']\n",
        "        }\n",
        "\n",
        "        self.medication_database = {\n",
        "            'paracetamol': {\n",
        "                'th_name': '‡∏û‡∏≤‡∏£‡∏≤‡πÄ‡∏ã‡∏ï‡∏≤‡∏°‡∏≠‡∏•',\n",
        "                'uses': ['‡∏•‡∏î‡πÑ‡∏Ç‡πâ', '‡πÅ‡∏Å‡πâ‡∏õ‡∏ß‡∏î'],\n",
        "                'dosage': '500-1000 mg ‡∏ó‡∏∏‡∏Å 4-6 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á',\n",
        "                'warnings': ['‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 4000 mg ‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô', '‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÉ‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÇ‡∏£‡∏Ñ‡∏ï‡∏±‡∏ö']\n",
        "            },\n",
        "            'aspirin': {\n",
        "                'th_name': '‡πÅ‡∏≠‡∏™‡πÑ‡∏û‡∏£‡∏¥‡∏ô',\n",
        "                'uses': ['‡πÅ‡∏Å‡πâ‡∏õ‡∏ß‡∏î', '‡∏•‡∏î‡πÑ‡∏Ç‡πâ', '‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏•‡∏¥‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏î'],\n",
        "                'dosage': '325-650 mg ‡∏ó‡∏∏‡∏Å 4 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á',\n",
        "                'warnings': ['‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÄ‡∏î‡πá‡∏Å‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ 18 ‡∏õ‡∏µ', '‡∏£‡∏∞‡∏ß‡∏±‡∏á‡πÉ‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÇ‡∏£‡∏Ñ‡∏Å‡∏£‡∏∞‡πÄ‡∏û‡∏≤‡∏∞']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.first_aid_procedures = {\n",
        "            'cpr': {\n",
        "                'th_name': '‡∏Å‡∏≤‡∏£‡∏ä‡πà‡∏ß‡∏¢‡∏ü‡∏∑‡πâ‡∏ô‡∏Ñ‡∏∑‡∏ô‡∏ä‡∏µ‡∏û',\n",
        "                'steps': [\n",
        "                    '‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á',\n",
        "                    '‡πÇ‡∏ó‡∏£ 1669',\n",
        "                    '‡∏Å‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å 30 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á',\n",
        "                    '‡πÄ‡∏õ‡πà‡∏≤‡∏õ‡∏≤‡∏Å 2 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á',\n",
        "                    '‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏à‡∏∞‡∏°‡∏≤‡∏ñ‡∏∂‡∏á'\n",
        "                ]\n",
        "            },\n",
        "            'bleeding': {\n",
        "                'th_name': '‡∏Å‡∏≤‡∏£‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏î',\n",
        "                'steps': [\n",
        "                    '‡∏Å‡∏î‡πÅ‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏ú‡πâ‡∏≤‡∏™‡∏∞‡∏≠‡∏≤‡∏î',\n",
        "                    '‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏π‡∏á',\n",
        "                    '‡∏Å‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á 10-15 ‡∏ô‡∏≤‡∏ó‡∏µ',\n",
        "                    '‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡πÑ‡∏°‡πà‡∏´‡∏¢‡∏∏‡∏î ‡πÇ‡∏ó‡∏£ 1669'\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.health_tips = {\n",
        "            'prevention': [\n",
        "                '‡∏•‡πâ‡∏≤‡∏á‡∏°‡∏∑‡∏≠‡∏ö‡πà‡∏≠‡∏¢‡πÜ ‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏ö‡∏π‡πà',\n",
        "                '‡∏™‡∏ß‡∏°‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏Å‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏≠‡∏≠‡∏±‡∏î',\n",
        "                '‡∏≠‡∏≠‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏¢‡∏™‡∏°‡πà‡∏≥‡πÄ‡∏™‡∏°‡∏≠',\n",
        "                '‡∏ô‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏ö‡∏û‡∏±‡∏Å‡∏ú‡πà‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠',\n",
        "                '‡∏î‡∏∑‡πà‡∏°‡∏ô‡πâ‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠'\n",
        "            ],\n",
        "            'nutrition': [\n",
        "                '‡∏Å‡∏¥‡∏ô‡∏ú‡∏±‡∏Å‡∏ú‡∏•‡πÑ‡∏°‡πâ 5 ‡∏´‡∏°‡∏π‡πà',\n",
        "                '‡∏•‡∏î‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏´‡∏ß‡∏≤‡∏ô ‡∏°‡∏±‡∏ô ‡πÄ‡∏Ñ‡πá‡∏°',\n",
        "                '‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏õ‡∏£‡∏ï‡∏µ‡∏ô‡πÑ‡∏Ç‡∏°‡∏±‡∏ô‡∏ï‡πà‡∏≥',\n",
        "                '‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö 5 ‡∏´‡∏°‡∏π‡πà'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    def check_emergency_level(self, symptoms: List[str]) -> UrgencyLevel:\n",
        "        \"\"\"Check urgency level from symptoms\"\"\"\n",
        "        symptoms_lower = [s.lower() for s in symptoms]\n",
        "\n",
        "        for symptom in symptoms_lower:\n",
        "            if any(critical in symptom for critical in self.emergency_symptoms['critical']):\n",
        "                return UrgencyLevel.CRITICAL\n",
        "            elif any(high in symptom for high in self.emergency_symptoms['high']):\n",
        "                return UrgencyLevel.HIGH\n",
        "\n",
        "        return UrgencyLevel.MEDIUM\n",
        "\n",
        "    def get_possible_conditions(self, symptoms: List[str]) -> List[str]:\n",
        "        \"\"\"Get possible conditions based on symptoms\"\"\"\n",
        "        conditions = []\n",
        "        for symptom in symptoms:\n",
        "            symptom_lower = symptom.lower()\n",
        "            for key, diseases in self.symptom_disease_mapping.items():\n",
        "                if key in symptom_lower:\n",
        "                    conditions.extend(diseases)\n",
        "\n",
        "        return list(set(conditions))\n",
        "\n",
        "    def get_medication_info(self, medication_name: str) -> Dict:\n",
        "        \"\"\"Get medication information\"\"\"\n",
        "        med_name = medication_name.lower()\n",
        "\n",
        "        for key, info in self.medication_database.items():\n",
        "            if key in med_name or info['th_name'] in medication_name:\n",
        "                return info\n",
        "\n",
        "        return {\n",
        "            \"error\": f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤ {medication_name}\",\n",
        "            \"suggestion\": \"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏†‡∏™‡∏±‡∏ä‡∏Å‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏û‡∏ó‡∏¢‡πå\"\n",
        "        }\n",
        "\n",
        "    def get_first_aid_steps(self, emergency_type: str) -> List[str]:\n",
        "        \"\"\"Get first aid steps for emergency\"\"\"\n",
        "        emergency_lower = emergency_type.lower()\n",
        "\n",
        "        for key, info in self.first_aid_procedures.items():\n",
        "            if key in emergency_lower or any(term in emergency_lower for term in [info['th_name'], key]):\n",
        "                return info['steps']\n",
        "\n",
        "        return [\"‡πÇ‡∏ó‡∏£ 1669 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\"]\n",
        "\n",
        "    def get_health_recommendations(self, category: str = \"prevention\") -> List[str]:\n",
        "        \"\"\"Get health recommendations\"\"\"\n",
        "        return self.health_tips.get(category, self.health_tips['prevention'])\n",
        "\n",
        "# ========================= Enhanced Thai Medical AI Agent =========================\n",
        "\n",
        "class EnhancedThaiMedicalAI:\n",
        "    \"\"\"Main AI Agent class with multimodal capabilities\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"üöÄ Initializing Enhanced Thai Medical AI Agent...\")\n",
        "\n",
        "        # Initialize core components\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"üì± Device: {self.device}\")\n",
        "\n",
        "        # Initialize storage and compliance\n",
        "        self.profile_storage = UserProfileStorage()\n",
        "        self.pdpa = PDPACompliance()\n",
        "\n",
        "        # Initialize AI components\n",
        "        self.knowledge_base = EnhancedMedicalKnowledgeBase()\n",
        "        self.triage_system = EmergencyTriageSystem()\n",
        "        self.drug_checker = DrugInteractionChecker()\n",
        "        self.clarification_system = ClarificationSystem()\n",
        "        self.feedback_system = FeedbackLearningSystem()\n",
        "\n",
        "        # Initialize multimodal components\n",
        "        self.vision_analyzer = VisionAnalyzer()\n",
        "        self.audio_analyzer = AudioAnalyzer()\n",
        "\n",
        "        # Load main language model\n",
        "        self._load_thai_llm()\n",
        "\n",
        "        # Initialize conversation state\n",
        "        self.conversation_history = []\n",
        "        self.current_user_id = None\n",
        "        self.current_session = {}\n",
        "\n",
        "        print(\"‚úÖ Enhanced Thai Medical AI Agent initialized successfully!\")\n",
        "\n",
        "    def _load_thai_llm(self):\n",
        "\n",
        "        \"\"\"Load typhoon2.1-gemma3-4b model with PEFT adapter\"\"\"\n",
        "        try:\n",
        "            base_model_name = \"scb10x/typhoon2.1-gemma3-4b\"\n",
        "            adapter_path = \"/content/drive/MyDrive/V89Technology/typhoon21-gemma3-4b-medCare-finetuned/checkpoint-120\"\n",
        "\n",
        "            # Configure for T4 GPU efficiency\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_quant_type=\"nf4\",\n",
        "                bnb_4bit_use_double_quant=True,\n",
        "                bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "                llm_int8_threshold=6.0,\n",
        "            )\n",
        "\n",
        "            # Load tokenizer\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "            # Load base model\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                base_model_name,\n",
        "               quantization_config=quantization_config,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                trust_remote_code=True,\n",
        "                low_cpu_mem_usage=True,\n",
        "                #use_cache=False,\n",
        "            )\n",
        "\n",
        "            # Load PEFT adapter\n",
        "            from peft import PeftModel\n",
        "            self.model = PeftModel.from_pretrained(\n",
        "                self.model,\n",
        "                adapter_path,\n",
        "                adapter_name=\"medical_adapter\"\n",
        "            )\n",
        "\n",
        "            # Set model to evaluation mode\n",
        "            self.model.eval()\n",
        "\n",
        "            print(\"‚úÖ typhoon2.1-gemma3-4b model with medical PEFT adapter loaded successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading typhoon2.1-gemma3-4b LLM: {e}\")\n",
        "            # Fallback to pipeline\n",
        "            try:\n",
        "                self.pipeline = pipeline(\n",
        "                    \"text-generation\",\n",
        "                    model=\"scb10x/typhoon2.1-gemma3-4b\",\n",
        "                    device=0 if torch.cuda.is_available() else -1\n",
        "\t\t #use_cache=False\n",
        "                )\n",
        "                self.model = None\n",
        "                self.tokenizer = None\n",
        "                print(\"‚úÖ Fallback model loaded\")\n",
        "            except:\n",
        "                self.model = None\n",
        "                self.tokenizer = None\n",
        "                self.pipeline = None\n",
        "                print(\"‚ùå No language model available\")\n",
        "\n",
        "\n",
        "    def create_user_session(self, user_data: Dict) -> str:\n",
        "        \"\"\"Create new user session with consent management\"\"\"\n",
        "        # Request basic consent\n",
        "        consent_request = self.pdpa.request_consent(\n",
        "            user_data.get('temp_id', str(uuid.uuid4())),\n",
        "            ConsentType.DATA_COLLECTION\n",
        "        )\n",
        "\n",
        "        return consent_request['consent_id']\n",
        "\n",
        "    def process_consent(self, consent_id: str, granted: bool, user_data: Dict) -> Dict:\n",
        "        \"\"\"Process user consent and create profile if granted\"\"\"\n",
        "        if granted:\n",
        "            # Create user profile\n",
        "            profile = self.profile_storage.create_user_profile(user_data)\n",
        "            self.current_user_id = profile.user_id\n",
        "\n",
        "            # Record consent\n",
        "            user_consent = UserConsent(\n",
        "                user_id=profile.user_id,\n",
        "                consent_type=ConsentType.DATA_COLLECTION,\n",
        "                granted=True,\n",
        "                timestamp=datetime.now()\n",
        "            )\n",
        "            self.pdpa.record_consent(user_consent)\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"user_id\": profile.user_id,\n",
        "                \"message\": \"‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö! ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢\"\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"message\": \"‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• ‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏à‡∏≥‡∏Å‡∏±‡∏î\"\n",
        "            }\n",
        "\n",
        "    def process_multimodal_input(self, text: str = \"\", image_path: str = \"\", audio_path: str = \"\") -> Dict:\n",
        "        \"\"\"Process multimodal input with Chain of Thought reasoning\"\"\"\n",
        "\n",
        "        # Chain of Thought reasoning steps\n",
        "        cot_analysis = {\n",
        "            \"step_1_input_analysis\": {},\n",
        "            \"step_2_symptom_extraction\": {},\n",
        "            \"step_3_multimodal_fusion\": {},\n",
        "            \"step_4_medical_reasoning\": {},\n",
        "            \"step_5_recommendation\": {}\n",
        "        }\n",
        "\n",
        "        # Step 1: Analyze each input modality\n",
        "        if text:\n",
        "            cot_analysis[\"step_1_input_analysis\"][\"text\"] = {\n",
        "                \"content\": text,\n",
        "                \"language\": \"thai\" if any('\\u0e00' <= char <= '\\u0e7f' for char in text) else \"english\",\n",
        "                \"length\": len(text.split()),\n",
        "                \"urgency_keywords\": [word for word in text.split() if word in [\"‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô\", \"‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô\", \"emergency\"]]\n",
        "            }\n",
        "\n",
        "        if image_path:\n",
        "            image_analysis = self.vision_analyzer.analyze_image(image_path)\n",
        "            cot_analysis[\"step_1_input_analysis\"][\"image\"] = image_analysis\n",
        "\n",
        "        if audio_path:\n",
        "            audio_analysis = self.audio_analyzer.analyze_audio(audio_path)\n",
        "            cot_analysis[\"step_1_input_analysis\"][\"audio\"] = audio_analysis\n",
        "\n",
        "        # Step 2: Extract symptoms from all modalities\n",
        "        symptoms = []\n",
        "        if text:\n",
        "            text_symptoms = self._extract_symptoms_from_text(text)\n",
        "            symptoms.extend(text_symptoms)\n",
        "            cot_analysis[\"step_2_symptom_extraction\"][\"text_symptoms\"] = text_symptoms\n",
        "\n",
        "        if image_path and \"findings\" in cot_analysis[\"step_1_input_analysis\"].get(\"image\", {}):\n",
        "            image_symptoms = cot_analysis[\"step_1_input_analysis\"][\"image\"][\"findings\"]\n",
        "            symptoms.extend(image_symptoms)\n",
        "            cot_analysis[\"step_2_symptom_extraction\"][\"image_symptoms\"] = image_symptoms\n",
        "\n",
        "        if audio_path and \"medical_indicators\" in cot_analysis[\"step_1_input_analysis\"].get(\"audio\", {}):\n",
        "            audio_symptoms = cot_analysis[\"step_1_input_analysis\"][\"audio\"][\"medical_indicators\"]\n",
        "            symptoms.extend(audio_symptoms)\n",
        "            cot_analysis[\"step_2_symptom_extraction\"][\"audio_symptoms\"] = audio_symptoms\n",
        "\n",
        "        # Step 3: Fuse multimodal information\n",
        "        confidence_scores = {}\n",
        "        if text and image_path:\n",
        "            # Cross-validate symptoms between text and image\n",
        "            text_set = set(cot_analysis[\"step_2_symptom_extraction\"].get(\"text_symptoms\", []))\n",
        "            image_set = set(cot_analysis[\"step_2_symptom_extraction\"].get(\"image_symptoms\", []))\n",
        "            overlap = text_set.intersection(image_set)\n",
        "            if overlap:\n",
        "                confidence_scores[\"cross_modal_validation\"] = len(overlap) / len(text_set.union(image_set))\n",
        "\n",
        "        cot_analysis[\"step_3_multimodal_fusion\"] = {\n",
        "            \"total_symptoms\": symptoms,\n",
        "            \"confidence_scores\": confidence_scores,\n",
        "            \"modalities_used\": [k for k in [\"text\", \"image\", \"audio\"] if k in cot_analysis[\"step_1_input_analysis\"]]\n",
        "        }\n",
        "\n",
        "        # Step 4: Medical reasoning\n",
        "        urgency = self.triage_system.assess_urgency(text, cot_analysis[\"step_1_input_analysis\"].get(\"image\"))\n",
        "        possible_conditions = self.knowledge_base.get_possible_conditions(symptoms)\n",
        "        emergency_level = self.knowledge_base.check_emergency_level(symptoms)\n",
        "\n",
        "        cot_analysis[\"step_4_medical_reasoning\"] = {\n",
        "            \"urgency_level\": urgency,\n",
        "            \"possible_conditions\": possible_conditions,\n",
        "            \"emergency_assessment\": emergency_level.value,\n",
        "            \"requires_immediate_attention\": emergency_level in [UrgencyLevel.CRITICAL, UrgencyLevel.HIGH]\n",
        "        }\n",
        "\n",
        "        # Step 5: Generate recommendations\n",
        "        recommendations = self._generate_recommendations(cot_analysis)\n",
        "        cot_analysis[\"step_5_recommendation\"] = recommendations\n",
        "\n",
        "        return cot_analysis\n",
        "\n",
        "    def _extract_symptoms_from_text(self, text: str) -> List[str]:\n",
        "        \"\"\"Extract symptoms from text using Thai NLP\"\"\"\n",
        "        symptoms = []\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Define symptom patterns\n",
        "        symptom_patterns = {\n",
        "            '‡πÑ‡∏Ç‡πâ': ['‡πÑ‡∏Ç‡πâ', '‡∏£‡πâ‡∏≠‡∏ô', 'fever', 'temperature'],\n",
        "            '‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß': ['‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß', 'headache', '‡∏´‡∏±‡∏ß‡πÄ‡∏à‡πá‡∏ö'],\n",
        "            '‡πÑ‡∏≠': ['‡πÑ‡∏≠', 'cough', 'ho'],\n",
        "            '‡πÄ‡∏à‡πá‡∏ö‡∏Ñ‡∏≠': ['‡πÄ‡∏à‡πá‡∏ö‡∏Ñ‡∏≠', '‡∏Ñ‡∏≠‡πÅ‡∏´‡πâ‡∏á', 'sore throat'],\n",
        "            '‡∏ß‡∏¥‡∏á‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô': ['‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô‡∏´‡∏±‡∏ß', '‡∏ß‡∏¥‡∏á‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô', 'dizzy'],\n",
        "            '‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢': ['‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢', '‡∏≠‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏•‡∏µ‡∏¢', 'tired', 'fatigue'],\n",
        "            '‡∏Ñ‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏™‡πâ': ['‡∏Ñ‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏™‡πâ', '‡∏≠‡∏¢‡∏≤‡∏Å‡∏≠‡∏≤‡πÄ‡∏à‡∏µ‡∏¢‡∏ô', 'nausea'],\n",
        "            '‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á': ['‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á', '‡∏ó‡πâ‡∏≠‡∏á‡πÄ‡∏à‡πá‡∏ö', 'abdominal pain'],\n",
        "            '‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏•‡∏≥‡∏ö‡∏≤‡∏Å': ['‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏•‡∏≥‡∏ö‡∏≤‡∏Å', '‡∏´‡∏≠‡∏ö‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢', 'breathing difficulty']\n",
        "        }\n",
        "\n",
        "        for symptom, patterns in symptom_patterns.items():\n",
        "            if any(pattern in text_lower for pattern in patterns):\n",
        "                symptoms.append(symptom)\n",
        "\n",
        "        return symptoms\n",
        "\n",
        "    def _generate_recommendations(self, cot_analysis: Dict) -> Dict:\n",
        "        \"\"\"Generate medical recommendations based on CoT analysis\"\"\"\n",
        "        recommendations = {\n",
        "            \"immediate_actions\": [],\n",
        "            \"medical_advice\": [],\n",
        "            \"lifestyle_recommendations\": [],\n",
        "            \"follow_up\": [],\n",
        "            \"emergency_warning\": None\n",
        "        }\n",
        "\n",
        "        emergency_level = cot_analysis[\"step_4_medical_reasoning\"][\"emergency_assessment\"]\n",
        "\n",
        "        # Emergency recommendations\n",
        "        if emergency_level == \"critical\":\n",
        "            recommendations[\"immediate_actions\"] = [\n",
        "                \"üö® ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏£‡∏ñ‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡πÇ‡∏ó‡∏£ 1669\",\n",
        "                \"üè• ‡πÑ‡∏õ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\",\n",
        "                \"üìû ‡πÅ‡∏à‡πâ‡∏á‡∏ç‡∏≤‡∏ï‡∏¥‡πÉ‡∏Å‡∏•‡πâ‡∏ä‡∏¥‡∏î\"\n",
        "            ]\n",
        "            recommendations[\"emergency_warning\"] = \"‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô - ‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\"\n",
        "\n",
        "        elif emergency_level == \"high\":\n",
        "            recommendations[\"immediate_actions\"] = [\n",
        "                \"üè• ‡πÑ‡∏õ‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ\",\n",
        "                \"üìã ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏¢‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏¥‡∏ô\",\n",
        "                \"üìû ‡πÇ‡∏ó‡∏£‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÑ‡∏õ\"\n",
        "            ]\n",
        "\n",
        "        # General medical advice based on symptoms\n",
        "        symptoms = cot_analysis[\"step_3_multimodal_fusion\"][\"total_symptoms\"]\n",
        "\n",
        "        if \"‡πÑ‡∏Ç‡πâ\" in symptoms:\n",
        "            recommendations[\"medical_advice\"].extend([\n",
        "                \"üíä ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ó‡∏≤‡∏ô‡∏¢‡∏≤‡∏•‡∏î‡πÑ‡∏Ç‡πâ‡∏ï‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\",\n",
        "                \"üå°Ô∏è ‡∏ß‡∏±‡∏î‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢‡∏ó‡∏∏‡∏Å 4 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á\",\n",
        "                \"üíß ‡∏î‡∏∑‡πà‡∏°‡∏ô‡πâ‡∏≥‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠\"\n",
        "            ])\n",
        "\n",
        "        if \"‡πÑ‡∏≠\" in symptoms:\n",
        "            recommendations[\"medical_advice\"].extend([\n",
        "                \"üçØ ‡∏î‡∏∑‡πà‡∏°‡∏ô‡πâ‡∏≥‡∏≠‡∏∏‡πà‡∏ô‡∏ú‡∏™‡∏°‡∏ô‡πâ‡∏≥‡∏ú‡∏∂‡πâ‡∏á\",\n",
        "                \"üö≠ ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏ß‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏ù‡∏∏‡πà‡∏ô\",\n",
        "                \"üò∑ ‡∏™‡∏ß‡∏°‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏Å‡∏≠‡∏ô‡∏≤‡∏°‡∏±‡∏¢\"\n",
        "            ])\n",
        "\n",
        "        if \"‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß\" in symptoms:\n",
        "            recommendations[\"medical_advice\"].extend([\n",
        "                \"üò¥ ‡∏û‡∏±‡∏Å‡∏ú‡πà‡∏≠‡∏ô‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡πÅ‡∏•‡∏∞‡∏°‡∏∑‡∏î\",\n",
        "                \"üíÜ ‡∏õ‡∏£‡∏∞‡∏Ñ‡∏ö‡πÄ‡∏¢‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏ú‡∏≤‡∏Å\",\n",
        "                \"üíä ‡∏ó‡∏≤‡∏ô‡∏¢‡∏≤‡πÅ‡∏Å‡πâ‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á\"\n",
        "            ])\n",
        "\n",
        "        # Lifestyle recommendations\n",
        "        recommendations[\"lifestyle_recommendations\"] = [\n",
        "            \"ü•ó ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏ó‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå\",\n",
        "            \"üí§ ‡∏ô‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ 7-9 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á\",\n",
        "            \"üö∂‚Äç‚ôÇÔ∏è ‡∏≠‡∏≠‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏¢‡πÄ‡∏ö‡∏≤‡πÜ ‡∏´‡∏≤‡∏Å‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô\",\n",
        "            \"üßò‚Äç‚ôÄÔ∏è ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î\"\n",
        "        ]\n",
        "\n",
        "        # Follow-up recommendations\n",
        "        if emergency_level in [\"medium\", \"low\"]:\n",
        "            recommendations[\"follow_up\"] = [\n",
        "                \"üìÖ ‡∏ô‡∏±‡∏î‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ô 2-3 ‡∏ß‡∏±‡∏ô\",\n",
        "                \"üìù ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á\",\n",
        "                \"üè• ‡πÑ‡∏õ‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏´‡∏≤‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô\"\n",
        "            ]\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def generate_response(self, input_text: str, context: Dict = None) -> str:\n",
        "        \"\"\"Generate response using typhoon2.1-gemma3-4b with medical context\"\"\"\n",
        "        if not self.model and not self.pipeline:\n",
        "            return self._generate_rule_based_response(input_text, context)\n",
        "\n",
        "        # Prepare medical context\n",
        "        medical_context = \"\"\n",
        "        if context:\n",
        "            if \"symptoms\" in context:\n",
        "                medical_context += f\"‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏û‡∏ö: {', '.join(context['symptoms'])}\\n\"\n",
        "            if \"urgency\" in context:\n",
        "                medical_context += f\"‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô: {context['urgency']}\\n\"\n",
        "            if \"recommendations\" in context:\n",
        "                medical_context += f\"‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: {context['recommendations']}\\n\"\n",
        "\n",
        "        # Create prompt for Thai medical assistant (typhoon2.1-gemma3-4b format)\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏û‡∏ó‡∏¢‡πå AI ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{medical_context}\\n\\n{input_text}\"}\n",
        "        ]\n",
        "\n",
        "        # Format for typhoon2.1-gemma3-4b\n",
        "        text = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            if self.model and self.tokenizer:\n",
        "                inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=2048, truncation=True)\n",
        "                inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = self.model.generate(\n",
        "                        **inputs,\n",
        "                        max_new_tokens=512,\n",
        "                        temperature=0.7,\n",
        "                        do_sample=True,\n",
        "                        pad_token_id=self.tokenizer.eos_token_id,\n",
        "                        repetition_penalty=1.1,\n",
        "                        top_p=0.9,\n",
        "\t\t     use_cache=True\n",
        "                    )\n",
        "\n",
        "                response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "                # Extract only the assistant's response\n",
        "                response = response.split(\"<|im_start|>assistant\\n\")[-1].strip()\n",
        "                response = response.split(\"<|im_end|>\")[0].strip()\n",
        "\n",
        "            else:\n",
        "                # Use pipeline fallback\n",
        "                result = self.pipeline(text, max_length=200, temperature=0.7)\n",
        "                response = result[0]['generated_text'].split(\"assistant\\n\")[-1].strip()\n",
        "\n",
        "            return response if response else self._generate_rule_based_response(input_text, context)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in text generation: {e}\")\n",
        "            return self._generate_rule_based_response(input_text, context)\n",
        "\n",
        "    def _generate_rule_based_response(self, input_text: str, context: Dict = None) -> str:\n",
        "        \"\"\"Generate rule-based response as fallback\"\"\"\n",
        "        responses = [\n",
        "            \"‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏â‡∏±‡∏ô‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\",\n",
        "            \"‡∏à‡∏≤‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏à‡πâ‡∏á‡∏°‡∏≤ ‡∏â‡∏±‡∏ô‡∏Ç‡∏≠‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏õ\",\n",
        "            \"‡∏´‡∏≤‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏Ç‡∏∂‡πâ‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\"\n",
        "        ]\n",
        "\n",
        "        if context and context.get(\"emergency_level\") == \"critical\":\n",
        "            return \"üö® ‡∏à‡∏≤‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏à‡πâ‡∏á‡∏°‡∏≤‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÑ‡∏õ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏ó‡∏£ 1669 ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\"\n",
        "\n",
        "        return responses[0]\n",
        "\n",
        "    def ask_clarification(self, symptoms: List[str]) -> Optional[ClarificationQuestion]:\n",
        "        \"\"\"Ask clarification questions\"\"\"\n",
        "        context = {\n",
        "            \"severity\": \"medium\",\n",
        "            \"duration\": \"unknown\"\n",
        "        }\n",
        "        return self.clarification_system.generate_clarification(symptoms, context)\n",
        "\n",
        "    def process_feedback(self, interaction_id: str, feedback_data: Dict) -> Dict:\n",
        "        \"\"\"Process user feedback\"\"\"\n",
        "        if not self.current_user_id:\n",
        "            return {\"error\": \"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\"}\n",
        "\n",
        "        feedback = self.feedback_system.collect_feedback(\n",
        "            interaction_id, self.current_user_id, feedback_data\n",
        "        )\n",
        "\n",
        "        # Store in database\n",
        "        self.profile_storage.store_feedback(feedback)\n",
        "\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"message\": \"‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞ ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£\"\n",
        "        }\n",
        "\n",
        "    def get_conversation_summary(self) -> Dict:\n",
        "        \"\"\"Get conversation summary and analytics\"\"\"\n",
        "        return {\n",
        "            \"total_interactions\": len(self.conversation_history),\n",
        "            \"current_user\": self.current_user_id,\n",
        "            \"performance_metrics\": self.feedback_system.get_performance_report(),\n",
        "            \"session_duration\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "# ========================= Gradio Interface =========================\n",
        "\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create Gradio interface for the medical AI\"\"\"\n",
        "\n",
        "    # Initialize the AI agent\n",
        "    medical_ai = EnhancedThaiMedicalAI()\n",
        "\n",
        "    def process_chat(message, history, image, audio):\n",
        "        \"\"\"Process chat with multimodal input\"\"\"\n",
        "        try:\n",
        "            # Handle file uploads\n",
        "            image_path = image.name if image else \"\"\n",
        "            audio_path = audio.name if audio else \"\"\n",
        "\n",
        "            # Process multimodal input with CoT\n",
        "            cot_result = medical_ai.process_multimodal_input(\n",
        "                text=message,\n",
        "                image_path=image_path,\n",
        "                audio_path=audio_path\n",
        "            )\n",
        "\n",
        "            # Extract recommendations\n",
        "            recommendations = cot_result[\"step_5_recommendation\"]\n",
        "\n",
        "            # Generate AI response\n",
        "            context = {\n",
        "                \"symptoms\": cot_result[\"step_3_multimodal_fusion\"][\"total_symptoms\"],\n",
        "                \"urgency\": cot_result[\"step_4_medical_reasoning\"][\"urgency_level\"],\n",
        "                \"emergency_level\": cot_result[\"step_4_medical_reasoning\"][\"emergency_assessment\"],\n",
        "                \"recommendations\": recommendations\n",
        "            }\n",
        "\n",
        "            ai_response = medical_ai.generate_response(message, context)\n",
        "\n",
        "            # Format response\n",
        "            response_parts = [ai_response]\n",
        "\n",
        "            # Add emergency warning if needed\n",
        "            if recommendations.get(\"emergency_warning\"):\n",
        "                response_parts.insert(0, f\"‚ö†Ô∏è {recommendations['emergency_warning']}\")\n",
        "\n",
        "            # Add immediate actions\n",
        "            if recommendations[\"immediate_actions\"]:\n",
        "                response_parts.append(\"\\nüö® ‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ô‡∏ó‡∏µ:\")\n",
        "                response_parts.extend([f\"‚Ä¢ {action}\" for action in recommendations[\"immediate_actions\"]])\n",
        "\n",
        "            # Add medical advice\n",
        "            if recommendations[\"medical_advice\"]:\n",
        "                response_parts.append(\"\\nüí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå:\")\n",
        "                response_parts.extend([f\"‚Ä¢ {advice}\" for advice in recommendations[\"medical_advice\"]])\n",
        "\n",
        "            # Add follow-up\n",
        "            if recommendations[\"follow_up\"]:\n",
        "                response_parts.append(\"\\nüìã ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°:\")\n",
        "                response_parts.extend([f\"‚Ä¢ {follow}\" for follow in recommendations[\"follow_up\"]])\n",
        "\n",
        "            final_response = \"\\n\".join(response_parts)\n",
        "\n",
        "            # Update conversation history\n",
        "            history.append([message, final_response])\n",
        "\n",
        "            return \"\", history, None, None\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}\\n‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á\"\n",
        "            history.append([message, error_msg])\n",
        "            return \"\", history, None, None\n",
        "\n",
        "    def submit_feedback(rating, helpful, accurate, comments):\n",
        "        \"\"\"Submit user feedback\"\"\"\n",
        "        try:\n",
        "            feedback_data = {\n",
        "                \"rating\": rating,\n",
        "                \"helpful\": helpful == \"Yes\",\n",
        "                \"accurate\": accurate == \"Yes\",\n",
        "                \"comments\": comments\n",
        "            }\n",
        "\n",
        "            # For demo, use a dummy interaction ID\n",
        "            interaction_id = str(uuid.uuid4())\n",
        "            result = medical_ai.process_feedback(interaction_id, feedback_data)\n",
        "\n",
        "            return \"‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞: {str(e)}\"\n",
        "\n",
        "    def create_user_profile(name, age, gender, medical_history, medications, allergies):\n",
        "        \"\"\"Create user profile\"\"\"\n",
        "        try:\n",
        "            user_data = {\n",
        "                \"name\": name,\n",
        "                \"age\": int(age) if age else 0,\n",
        "                \"gender\": gender,\n",
        "                \"medical_history\": medical_history.split(\",\") if medical_history else [],\n",
        "                \"medications\": medications.split(\",\") if medications else [],\n",
        "                \"allergies\": allergies.split(\",\") if allergies else []\n",
        "            }\n",
        "\n",
        "            consent_id = medical_ai.create_user_session(user_data)\n",
        "\n",
        "            # For demo, automatically grant consent\n",
        "            result = medical_ai.process_consent(consent_id, True, user_data)\n",
        "\n",
        "            if result[\"success\"]:\n",
        "                return f\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! User ID: {result['user_id'][:8]}...\"\n",
        "            else:\n",
        "                return result[\"message\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}\"\n",
        "\n",
        "    # Create Gradio interface\n",
        "    with gr.Blocks(\n",
        "        title=\"Enhanced Thai Medical Care AI Agent\",\n",
        "        theme=gr.themes.Soft(),\n",
        "        css=\"\"\"\n",
        "        .container { max-width: 1200px; margin: auto; }\n",
        "        .emergency { background-color: #fee; border-left: 4px solid #f00; padding: 10px; }\n",
        "        .warning { background-color: #ffeaa7; border-left: 4px solid #f39c12; padding: 10px; }\n",
        "        \"\"\"\n",
        "    ) as demo:\n",
        "\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            # üè• ‡∏£‡∏∞‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "            ## Enhanced Thai Medical Care AI Agent Chat Multi-Modal with Chain of Thought\n",
        "\n",
        "            **‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö:**\n",
        "            - ‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
        "            - ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏î‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÑ‡∏î‡πâ\n",
        "            - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        with gr.Tabs():\n",
        "            # Chat Interface\n",
        "            with gr.TabItem(\"üí¨ ‡πÅ‡∏ä‡∏ó‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=2):\n",
        "                        chatbot = gr.Chatbot(\n",
        "                            height=500,\n",
        "                            label=\"‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤\",\n",
        "                            placeholder=\"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏°‡∏û‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì...\"\n",
        "                        )\n",
        "\n",
        "                        with gr.Row():\n",
        "                            msg = gr.Textbox(\n",
        "                                label=\"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\",\n",
        "                                placeholder=\"‡∏û‡∏¥‡∏°‡∏û‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì...\",\n",
        "                                lines=2\n",
        "                            )\n",
        "\n",
        "                        with gr.Row():\n",
        "                            image_input = gr.File(\n",
        "                                label=\"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û (‡πÄ‡∏ä‡πà‡∏ô ‡∏ú‡∏∑‡πà‡∏ô, ‡πÅ‡∏ú‡∏•, ‡∏Ø‡∏•‡∏Ø)\",\n",
        "                                file_types=[\"image\"]\n",
        "                            )\n",
        "                            audio_input = gr.File(\n",
        "                                label=\"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏≠, ‡∏´‡∏≤‡∏¢‡πÉ‡∏à)\",\n",
        "                                file_types=[\"audio\"]\n",
        "                            )\n",
        "\n",
        "                        submit_btn = gr.Button(\"‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\", variant=\"primary\")\n",
        "\n",
        "                # Process chat\n",
        "                submit_btn.click(\n",
        "                    process_chat,\n",
        "                    inputs=[msg, chatbot, image_input, audio_input],\n",
        "                    outputs=[msg, chatbot, image_input, audio_input]\n",
        "                )\n",
        "\n",
        "                msg.submit(\n",
        "                    process_chat,\n",
        "                    inputs=[msg, chatbot, image_input, audio_input],\n",
        "                    outputs=[msg, chatbot, image_input, audio_input]\n",
        "                )\n",
        "\n",
        "            # User Profile\n",
        "            with gr.TabItem(\"üë§ ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\"):\n",
        "                gr.Markdown(\"### ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Ñ‡∏∏‡∏ì\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        profile_name = gr.Textbox(label=\"‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•\")\n",
        "                        profile_age = gr.Number(label=\"‡∏≠‡∏≤‡∏¢‡∏∏\", minimum=0, maximum=150)\n",
        "                        profile_gender = gr.Dropdown(\n",
        "                            label=\"‡πÄ‡∏û‡∏®\",\n",
        "                            choices=[\"‡∏ä‡∏≤‡∏¢\", \"‡∏´‡∏ç‡∏¥‡∏á\", \"‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏\"]\n",
        "                        )\n",
        "\n",
        "                    with gr.Column():\n",
        "                        profile_medical_history = gr.Textbox(\n",
        "                            label=\"‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡πá‡∏ö‡∏õ‡πà‡∏ß‡∏¢ (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤)\",\n",
        "                            placeholder=\"‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏ö‡∏≤‡∏´‡∏ß‡∏≤‡∏ô, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡∏±‡∏ô‡πÇ‡∏•‡∏´‡∏¥‡∏ï‡∏™‡∏π‡∏á\"\n",
        "                        )\n",
        "                        profile_medications = gr.Textbox(\n",
        "                            label=\"‡∏¢‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏¥‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤)\",\n",
        "                            placeholder=\"‡πÄ‡∏ä‡πà‡∏ô metformin, amlodipine\"\n",
        "                        )\n",
        "                        profile_allergies = gr.Textbox(\n",
        "                            label=\"‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡πâ‡∏¢‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏≤‡∏£‡∏≠‡∏∑‡πà‡∏ô‡πÜ (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤)\",\n",
        "                            placeholder=\"‡πÄ‡∏ä‡πà‡∏ô penicillin, ‡∏Å‡∏∏‡πâ‡∏á, ‡πÑ‡∏Ç‡πà\"\n",
        "                        )\n",
        "\n",
        "                create_profile_btn = gr.Button(\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå\", variant=\"primary\")\n",
        "                profile_status = gr.Textbox(label=\"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞\", interactive=False)\n",
        "\n",
        "                create_profile_btn.click(\n",
        "                    create_user_profile,\n",
        "                    inputs=[profile_name, profile_age, profile_gender, profile_medical_history, profile_medications, profile_allergies],\n",
        "                    outputs=[profile_status]\n",
        "                )\n",
        "\n",
        "            # Feedback Interface\n",
        "            with gr.TabItem(\"üìù ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô\"):\n",
        "                gr.Markdown(\"### ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        feedback_rating = gr.Slider(\n",
        "                            label=\"‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏≠‡πÉ‡∏à\",\n",
        "                            minimum=1,\n",
        "                            maximum=5,\n",
        "                            step=1,\n",
        "                            value=3\n",
        "                        )\n",
        "                        feedback_helpful = gr.Radio(\n",
        "                            label=\"‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?\",\n",
        "                            choices=[\"Yes\", \"No\"],\n",
        "                            value=\"Yes\"\n",
        "                        )\n",
        "                        feedback_accurate = gr.Radio(\n",
        "                            label=\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?\",\n",
        "                            choices=[\"Yes\", \"No\"],\n",
        "                            value=\"Yes\"\n",
        "                        )\n",
        "\n",
        "                    with gr.Column():\n",
        "                        feedback_comments = gr.Textbox(\n",
        "                            label=\"‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°\",\n",
        "                            lines=4,\n",
        "                            placeholder=\"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏£‡∏∞‡∏ö‡∏ö...\"\n",
        "                        )\n",
        "\n",
        "                submit_feedback_btn = gr.Button(\"‡∏™‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô\", variant=\"primary\")\n",
        "                feedback_status = gr.Textbox(label=\"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞\", interactive=False)\n",
        "\n",
        "                submit_feedback_btn.click(\n",
        "                    submit_feedback,\n",
        "                    inputs=[feedback_rating, feedback_helpful, feedback_accurate, feedback_comments],\n",
        "                    outputs=[feedback_status]\n",
        "                )\n",
        "\n",
        "            # Emergency Information\n",
        "            with gr.TabItem(\"üö® ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô\"):\n",
        "                gr.Markdown(\"\"\"\n",
        "                ### üìû ‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô\n",
        "\n",
        "                **üöë ‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô:**\n",
        "                - **1669** - ‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ô‡πÄ‡∏£‡∏ô‡∏ó‡∏£‡πå‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô (24 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á)\n",
        "                - **1646** - ‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå\n",
        "\n",
        "                **üè• ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•:**\n",
        "                - **‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•:** 1668\n",
        "                - **‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤:** 1556\n",
        "\n",
        "                **üè• ‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•:**\n",
        "                - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ: 038-274-100\n",
        "                - ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏û‡∏±‡∏ó‡∏¢‡∏≤: 038-429-422\n",
        "                - ‡πÇ‡∏£‡∏á‡∏ûy‡∏≤‡∏ö‡∏≤‡∏•‡∏™‡∏°‡∏¥‡∏ï‡∏¥‡πÄ‡∏ß‡∏ä: 038-235-000\n",
        "\n",
        "                ### ü©∫ ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏µ‡∏ö‡πÑ‡∏õ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•\n",
        "\n",
        "                **üö® ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á:**\n",
        "                - ‡πÄ‡∏à‡πá‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á\n",
        "                - ‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å\n",
        "                - ‡∏ä‡∏±‡∏Å\n",
        "                - ‡∏´‡∏°‡∏î‡∏™‡∏ï‡∏¥\n",
        "                - ‡∏°‡∏µ‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏Å\n",
        "                - ‡∏≠‡∏≤‡πÄ‡∏à‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î\n",
        "                - ‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏â‡∏±‡∏ö‡∏û‡∏•‡∏±‡∏ô\n",
        "\n",
        "                **‚ö†Ô∏è ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡πá‡∏ß:**\n",
        "                - ‡πÑ‡∏Ç‡πâ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å (‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 39¬∞C)\n",
        "                - ‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥\n",
        "                - ‡∏ú‡∏∑‡πà‡∏ô‡πÅ‡∏û‡∏£‡πà‡∏á‡πÄ‡∏£‡πá‡∏ß\n",
        "                - ‡πÑ‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î\n",
        "                - ‡∏õ‡∏±‡∏™‡∏™‡∏≤‡∏ß‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏î\n",
        "\n",
        "                ### üè† ‡∏Å‡∏≤‡∏£‡∏õ‡∏ê‡∏°‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
        "\n",
        "                **üíî CPR:**\n",
        "                1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á\n",
        "                2. ‡πÇ‡∏ó‡∏£ 1669\n",
        "                3. ‡∏Å‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å 30 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n",
        "                4. ‡πÄ‡∏õ‡πà‡∏≤‡∏õ‡∏≤‡∏Å 2 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n",
        "                5. ‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡∏à‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏°‡∏≤‡∏ñ‡∏∂‡∏á\n",
        "\n",
        "                **ü©∏ ‡∏Å‡∏≤‡∏£‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏î:**\n",
        "                1. ‡∏Å‡∏î‡πÅ‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏ú‡πâ‡∏≤‡∏™‡∏∞‡∏≠‡∏≤‡∏î\n",
        "                2. ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏≤‡∏î‡πÄ‡∏à‡πá‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏π‡∏á\n",
        "                3. ‡∏Å‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á 10-15 ‡∏ô‡∏≤‡∏ó‡∏µ\n",
        "                4. ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡πÑ‡∏°‡πà‡∏´‡∏¢‡∏∏‡∏î ‡πÇ‡∏ó‡∏£ 1669\n",
        "\n",
        "                **üî• ‡πÅ‡∏ú‡∏•‡πÑ‡∏ü‡πÑ‡∏´‡∏°‡πâ:**\n",
        "                1. ‡∏•‡πâ‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡πâ‡∏≥‡πÄ‡∏¢‡πá‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\n",
        "                2. ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡πâ‡∏≠‡∏ô\n",
        "                3. ‡πÉ‡∏ä‡πâ‡∏ú‡πâ‡∏≤‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡∏•‡∏∏‡∏°\n",
        "                4. ‡πÑ‡∏õ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•‡∏´‡∏≤‡∏Å‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á\n",
        "                \"\"\")\n",
        "\n",
        "            # System Analytics\n",
        "            with gr.TabItem(\"üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏£‡∏∞‡∏ö‡∏ö\"):\n",
        "                gr.Markdown(\"### üìà ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏£‡∏∞‡∏ö‡∏ö\")\n",
        "\n",
        "                def get_system_stats():\n",
        "                    \"\"\"Get system statistics\"\"\"\n",
        "                    try:\n",
        "                        stats = medical_ai.get_conversation_summary()\n",
        "                        performance = stats[\"performance_metrics\"]\n",
        "\n",
        "                        return (\n",
        "                            f\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {stats['total_interactions']}\",\n",
        "                            f\"‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: {performance['accuracy']:.2%}\",\n",
        "                            f\"‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå: {performance['helpful_rate']:.2%}\",\n",
        "                            f\"‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {performance.get('average_rating', 0):.1f}/5.0\",\n",
        "                            f\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞: {performance['total_feedback']}\"\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        return (f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}\",) * 5\n",
        "\n",
        "                with gr.Row():\n",
        "                    stats_btn = gr.Button(\"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥\", variant=\"secondary\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        total_interactions = gr.Textbox(label=\"‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\", interactive=False)\n",
        "                        accuracy_rate = gr.Textbox(label=\"‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\", interactive=False)\n",
        "                        helpful_rate = gr.Textbox(label=\"‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå\", interactive=False)\n",
        "                    with gr.Column():\n",
        "                        avg_rating = gr.Textbox(label=\"‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢\", interactive=False)\n",
        "                        total_feedback = gr.Textbox(label=\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞\", interactive=False)\n",
        "\n",
        "                stats_btn.click(\n",
        "                    get_system_stats,\n",
        "                    outputs=[total_interactions, accuracy_rate, helpful_rate, avg_rating, total_feedback]\n",
        "                )\n",
        "\n",
        "            # Help and Documentation\n",
        "            with gr.TabItem(\"‚ùì ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\"):\n",
        "                gr.Markdown(\"\"\"\n",
        "                ## üìñ ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏£‡∏∞‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "\n",
        "                ### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå\n",
        "                ‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ AI ‡πÅ‡∏•‡∏∞ Multi-Modal Processing\n",
        "\n",
        "                ### üíª ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
        "\n",
        "                **1. üí¨ ‡πÅ‡∏ä‡∏ó‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤:**\n",
        "                - ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û\n",
        "                - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (‡πÅ‡∏ú‡∏•, ‡∏ú‡∏∑‡πà‡∏ô, ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥)\n",
        "                - ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏≠, ‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥)\n",
        "                - ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\n",
        "\n",
        "                **2. üë§ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå:**\n",
        "                - ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (‡∏ä‡∏∑‡πà‡∏≠, ‡∏≠‡∏≤‡∏¢‡∏∏, ‡πÄ‡∏û‡∏®)\n",
        "                - ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡πá‡∏ö‡∏õ‡πà‡∏ß‡∏¢\n",
        "                - ‡∏¢‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏¥‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n",
        "                - ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡πâ‡∏¢‡∏≤\n",
        "\n",
        "                **3. üìù ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô:**\n",
        "                - ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏≠‡πÉ‡∏à (1-5 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)\n",
        "                - ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "                - ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "                - ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°\n",
        "\n",
        "                ### üîß ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "\n",
        "                **üß† Chain of Thought (CoT) Processing:**\n",
        "                - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô\n",
        "                - ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡∏£‡∏π‡∏õ, ‡πÄ‡∏™‡∏µ‡∏¢‡∏á)\n",
        "                - ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
        "\n",
        "                **üîí PDPA Compliance:**\n",
        "                - ‡∏õ‡∏Å‡∏õ‡πâ‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢\n",
        "                - ‡∏Ç‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "                - ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç\n",
        "\n",
        "                **üö® Emergency Triage:**\n",
        "                - ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á\n",
        "                - ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô\n",
        "                - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\n",
        "\n",
        "                ### ‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
        "\n",
        "                **‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡πÑ‡∏î‡πâ:**\n",
        "                - ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
        "                - ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á‡∏≠‡∏≤‡∏Å‡∏≤‡∏£\n",
        "                - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏ê‡∏°‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•\n",
        "                - ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ\n",
        "\n",
        "                **‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:**\n",
        "                - ‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÇ‡∏£‡∏Ñ‡πÅ‡∏ó‡∏ô‡πÅ‡∏û‡∏ó‡∏¢‡πå\n",
        "                - ‡∏™‡∏±‡πà‡∏á‡∏à‡πà‡∏≤‡∏¢‡∏¢‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ\n",
        "                - ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á 100%\n",
        "                - ‡∏ó‡∏î‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
        "\n",
        "                ### üìû ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏ß‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå\n",
        "\n",
        "                **‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (‡πÇ‡∏ó‡∏£ 1669):**\n",
        "                - ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á\n",
        "                - ‡πÄ‡∏à‡πá‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏Å, ‡∏´‡∏≤‡∏¢‡πÉ‡∏à‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å\n",
        "                - ‡∏ä‡∏±‡∏Å, ‡∏´‡∏°‡∏î‡∏™‡∏ï‡∏¥\n",
        "                - ‡πÄ‡∏•‡∏∑‡∏≠‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏Å\n",
        "\n",
        "                **‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡πá‡∏ß (‡∏†‡∏≤‡∏¢‡πÉ‡∏ô 24 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á):**\n",
        "                - ‡πÑ‡∏Ç‡πâ‡∏™‡∏π‡∏á‡πÑ‡∏°‡πà‡∏•‡∏î\n",
        "                - ‡∏õ‡∏ß‡∏î‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á\n",
        "                - ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏Å‡πÉ‡∏´‡∏°‡πà\n",
        "                - ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏≤\n",
        "\n",
        "                ### üîç ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
        "\n",
        "                **ü§ñ AI Models:**\n",
        "                - **typhoon21-gemma3-4b** with Medical Fine-tuning ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "                - Vision Transformer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\n",
        "                - Whisper ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
        "\n",
        "                **üíæ Data Processing:**\n",
        "                - Natural Language Processing ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "                - Image Analysis ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏ú‡∏¥‡∏ß‡∏´‡∏ô‡∏±‡∏á\n",
        "                - Audio Analysis ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏≤‡∏¢‡πÉ‡∏à\n",
        "\n",
        "                **üõ°Ô∏è Security:**\n",
        "                - ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (AES-256)\n",
        "                - Audit Log ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö\n",
        "                - Anonymization ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•\n",
        "\n",
        "                ### üôã‚Äç‚ôÄÔ∏è ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢\n",
        "\n",
        "                **Q: ‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?**\n",
        "                A: ‡πÉ‡∏ä‡πà ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏ï‡∏≤‡∏° PDPA ‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "\n",
        "                **Q: ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?**\n",
        "                A: ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏Ñ‡∏ß‡∏£‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
        "\n",
        "                **Q: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏ô‡∏≤‡∏ô‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô?**\n",
        "                A: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ PDPA ‡πÅ‡∏•‡∏∞‡∏à‡∏∞‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏´‡∏°‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
        "\n",
        "                **Q: ‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?**\n",
        "                A: ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å ‡πÅ‡∏ï‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏î‡πâ\n",
        "\n",
        "                ### üìß ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°\n",
        "                ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏™‡∏á‡∏™‡∏±‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠:\n",
        "                - Email: support@v89tech.com\n",
        "                - Line: @v89tech\n",
        "                - ‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå: https://v89tech.com\n",
        "                \"\"\")\n",
        "\n",
        "        # Add footer\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "\n",
        "        ### üè• ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö\n",
        "\n",
        "        **‡∏£‡∏∞‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢** ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢:\n",
        "        - üî¨ ‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤: ‡∏ó‡∏µ‡∏°‡∏á‡∏≤‡∏ô Super AI Engineer SS5\n",
        "        - üè• ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå: ‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤\n",
        "        - üíª ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ: Python, Transformers, Gradio, Multi-Modal AI\n",
        "\n",
        "        **‚öñÔ∏è ‡∏Ç‡πâ‡∏≠‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö:**\n",
        "        ‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå\n",
        "        ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\n",
        "\n",
        "        **üîí ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß:** ‡πÄ‡∏£‡∏≤‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏Å‡∏õ‡πâ‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ï‡∏≤‡∏° ‡∏û.‡∏£.‡∏ö. PDPA\n",
        "\n",
        "        ** ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏ß‡∏µ89 ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ ‡∏à‡∏≥‡∏Å‡∏±‡∏î | **üìà‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô:** 2.0 - ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: ‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏° 2025\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "# ========================= Main Execution =========================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the medical AI system\"\"\"\n",
        "    print(\"üöÄ Starting Enhanced Thai Medical Care AI Agent...\")\n",
        "\n",
        "    try:\n",
        "        # Create and launch Gradio interface\n",
        "        demo = create_gradio_interface()\n",
        "\n",
        "        # Launch with configurations for Google Colab\n",
        "        demo.launch(\n",
        "            server_name=\"0.0.0.0\",  # Allow external access in Colab\n",
        "            server_port=7860,       # Default port\n",
        "            share=True,             # Create shareable link\n",
        "            debug=True,             # Enable debug mode\n",
        "            show_error=True,        # Show errors in interface\n",
        "            quiet=False,            # Show startup messages\n",
        "            height=1080,             # Interface height\n",
        "            favicon_path=None,      # Custom favicon (optional)\n",
        "            ssl_verify=False,       # Disable SSL verification for development\n",
        "            app_kwargs={\n",
        "                \"docs_url\": None,   # Disable FastAPI docs\n",
        "                \"redoc_url\": None   # Disable ReDoc\n",
        "            }\n",
        "        )\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nüõë System stopped by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error starting system: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        print(\"üëã Enhanced Thai Medical Care AI Agent shutdown complete\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Check if running in Google Colab\n",
        "    try:\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "        print(\"üì± Running in Google Colab environment\")\n",
        "    except ImportError:\n",
        "        IN_COLAB = False\n",
        "        print(\"üíª Running in local environment\")\n",
        "\n",
        "    # Set environment variables for better performance\n",
        "    import os\n",
        "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # Avoid tokenizer warnings\n",
        "    os.environ[\"TRANSFORMERS_CACHE\"] = \"/tmp/transformers_cache\"  # Cache directory\n",
        "\n",
        "    # Run the main application\n",
        "    main()"
      ],
      "metadata": {
        "id": "8QnHD6m1YuV1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}